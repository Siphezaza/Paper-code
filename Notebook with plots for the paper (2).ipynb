{"cells":[{"cell_type":"markdown","metadata":{"id":"BCiVLNaFS811"},"source":["# Imports"]},{"cell_type":"code","source":["!pip uninstall scikit-learn -y\n","!pip install scikit-learn==1.2.2"],"metadata":{"id":"_WIcM6yWgpY8"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"_xb2kCcfTD0I"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["pip install keras"],"metadata":{"id":"KwaNYWB4UR9m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install dill"],"metadata":{"id":"sVg7p3iYldyr"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install --upgrade --force-reinstall numpy\n","!pip install --upgrade --force-reinstall scikit-learn\n"],"metadata":{"id":"azZqAYALlLh5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip uninstall -y scipy scikit-learn numpy\n","!pip install numpy==1.24.4 scipy==1.10.1 scikit-learn==1.3.2\n"],"metadata":{"id":"wQFce97-mWtc"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lLfL3maVS818"},"outputs":[],"source":["# Import required libraries for building a neural network, data manipulation, and evaluation metrics\n","from keras.models import Sequential               # Sequential model to stack layers linearly\n","from keras.layers import Dense                    # Dense layer to create fully connected layers\n","from keras.optimizers import Adadelta             # Optimizer used to minimize the loss function\n","import numpy as np                                # NumPy for numerical operations\n","import pandas as pd                               # Pandas for data manipulation\n","from sklearn.preprocessing import MinMaxScaler    # Scaler to normalize features to a specific range\n","import matplotlib.pyplot as plt                   # Matplotlib for plotting\n","from sklearn.metrics import (                     # Metrics for model evaluation\n","    f1_score, accuracy_score, precision_score, recall_score, roc_auc_score, confusion_matrix\n",")\n","from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n","from sklearn.metrics import confusion_matrix, accuracy_score\n","from sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n","from tensorflow.keras.layers import Dropout\n","from sklearn.model_selection import ParameterGrid\n","from sklearn.model_selection import train_test_split  # For splitting datasets\n","from sklearn.metrics import confusion_matrix, accuracy_score\n","import json\n","from keras.models import Sequential\n","from keras.layers import Dense, Dropout\n","from tensorflow.keras.optimizers import Adam\n","import seaborn as sns\n","from sklearn.metrics import confusion_matrix\n","from matplotlib.backends.backend_pdf import PdfPages\n","import matplotlib.dates as mdates\n","from sklearn.ensemble import IsolationForest\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.metrics import roc_auc_score\n","import time\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n","from keras.models import load_model\n","import os\n","from sklearn.utils import resample\n","from sklearn.cluster import DBSCAN\n","import pickle\n","from tensorflow.keras.models import load_model\n","from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score, confusion_matrix, roc_auc_score\n","from sklearn.neighbors import LocalOutlierFactor\n","from sklearn.metrics import roc_curve, auc\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","from matplotlib.dates import DateFormatter"]},{"cell_type":"code","source":["#NN-AE model for data without augmentation\n","# Define the path to the model file\n","model_path = '/content/drive/MyDrive/Notebook_with_plots/autoencoder_model(original_batch_size_128_50epchs3).keras'\n","\n","# Check if the file exists\n","if os.path.exists(model_path):\n","    # Load the model\n","    model = load_model(model_path, compile=False)\n","else:\n","    print(\"Model file not found.\")\n","\n","\n","\n","    #Load model for IF\n","# Define the path to the model file\n","best_isolation_forest_model_path = '/content/drive/MyDrive/Notebook_with_plots/best_isolation_forest_model_original.pkl'\n","\n","# Check if the file exists\n","if os.path.exists(best_isolation_forest_model_path):\n","    # Load the saved model using dill\n","    import dill\n","    with open(best_isolation_forest_model_path, \"rb\") as model_file:\n","        loaded_isolation_forest_IF_original = dill.load(model_file)\n","else:\n","    print(\"Model file not found.\")\n","\n","\n","\n","#Load model for DBSCAN\n","# Define the paths to the files\n","best_params_path = '/content/drive/MyDrive/Notebook_with_plots/best_dbscan_params_90s.pkl'\n","dbscan_results_path = '/content/drive/MyDrive/Notebook_with_plots/dbscan_results_90s.pkl'\n","\n","if os.path.exists(best_params_path) and os.path.exists(dbscan_results_path):\n","    # Load the best parameters and evaluation results using dill\n","    import dill\n","    with open(best_params_path, \"rb\") as params_file:\n","        best_params = dill.load(params_file)\n","    with open(dbscan_results_path, \"rb\") as results_file:\n","        dbscan_results_DBSCAN_Original = dill.load(results_file)\n","else:\n","    print(\"One or more files not found.\")\n","\n","\n","#Load model for LOF\n","# Define the path to the file\n","best_lof_params_path = '/content/drive/MyDrive/Notebook_with_plots/best_lof_params_original.pkl'\n","import os\n","if os.path.exists(best_lof_params_path):\n","    with open(best_lof_params_path, \"rb\") as params_file:\n","        loaded_best_params_LOF_Original = dill.load(params_file)\n","else:\n","    print(\"File not found.\")\n","\n","\n","\n","#Load data without augmentation\n","# Define the path to the data file\n","data_path = '/content/drive/MyDrive/Notebook_with_plots/data_without_augmentation.txt'\n","\n","# Check if the file exists\n","import os\n","if os.path.exists(data_path):\n","    # Load the data\n","    import pandas as pd\n","    data = pd.read_csv(data_path, sep='\\t')\n","else:\n","    print(\"Data file not found.\")\n","\n","\n","\n","\n","# Define the path to the data files\n","test_data_path = '/content/drive/MyDrive/Notebook_with_plots/test_data_All.txt'\n","train_data_path = '/content/drive/MyDrive/Notebook_with_plots/training_NN-AE(original).txt'\n","validation_data_path = '/content/drive/MyDrive/Notebook_with_plots/validation_NN-AE(original).txt'\n","\n","# Check if the files exist\n","import os\n","if os.path.exists(test_data_path) and os.path.exists(train_data_path) and os.path.exists(validation_data_path):\n","    # Load the data\n","    import pandas as pd\n","    test_data = pd.read_csv(test_data_path, sep='\\t')\n","    train_data_final = pd.read_csv(train_data_path, sep='\\t')\n","    validation_data = pd.read_csv(validation_data_path, sep='\\t')\n","else:\n","    print(\"One or more data files not found.\")"],"metadata":{"id":"rFf-OoWn3gde"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"N8jDeF9gS81_"},"source":["# Global Functions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tPy9K6IuS82A"},"outputs":[],"source":["def calculate_metrics_for_multiple_percentiles(\n","    model,\n","    X_train_features_scaled, Y_train_labels,  # Training set\n","    X_test_features_scaled, Y_test_labels,    # Test set\n","    X_validation_set_2_features_scaled, Y_validation_set_2_labels,  # Validation set 2 for thresholds\n","    percentiles = [65]#[1, 2, 3, 4, 5, 6, 7, 8, 9, 10,11, 12, 13, 14, 15, 16, 17, 18, 19, 20,21, 22, 23, 24, 25, 26, 27,\n","                   #28, 29, 30,31, 32, 33, 34, 35, 36, 37, 38, 39, 40,41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52,\n","                   #53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70,71, 72, 73, 74, 75, 76, 77,\n","                   #78, 79, 80,81, 82, 83, 84, 85, 86, 87, 88, 89, 90,91, 92, 93, 94, 95, 96, 97, 98, 99, 100]\n","):\n","    # Initialize lists to store validation thresholds and results\n","    validation_thresholds = []\n","    results = []\n","\n","    # Step 1: Calculate validation thresholds for each percentile using validation set 2\n","    for percentile in percentiles:\n","        # Compute reconstruction errors for validation set 2\n","        val_predictions_2 = model.predict(X_validation_set_2_features_scaled)\n","        val_reconstruction_errors_2 = np.mean(np.square(X_validation_set_2_features_scaled - val_predictions_2), axis=1)\n","\n","        # Calculate threshold for the current percentile\n","        threshold = np.percentile(val_reconstruction_errors_2, percentile)\n","        validation_thresholds.append(threshold)\n","\n","    # Step 2: Validate using the calculated thresholds on the validation set\n","    for idx, percentile in enumerate(percentiles):\n","        threshold = validation_thresholds[idx]\n","\n","        # Compute reconstruction errors for the validation set\n","        val_predictions = model.predict(X_validation_set_2_features_scaled)\n","        val_reconstruction_errors = np.mean(np.square(X_validation_set_2_features_scaled - val_predictions), axis=1)\n","\n","        # Apply the threshold to classify validation samples\n","        y_val_pred = (val_reconstruction_errors > threshold).astype(int)\n","\n","        # Calculate metrics for the validation set\n","        val_accuracy = accuracy_score(Y_validation_set_2_labels, y_val_pred)\n","        precision = precision_score(Y_validation_set_2_labels, y_val_pred)\n","        recall = recall_score(Y_validation_set_2_labels, y_val_pred)\n","        f1 = f1_score(Y_validation_set_2_labels, y_val_pred)\n","\n","        # Specificity: True Negatives / (True Negatives + False Positives)\n","        tn, fp, fn, tp = confusion_matrix(Y_validation_set_2_labels, y_val_pred).ravel()\n","        specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n","\n","        # Store results for this percentile\n","        results.append({\n","            'Percentile': percentile,\n","            'Optimal Threshold': threshold,\n","            'Precision': precision,\n","            'Recall': recall,\n","            'F1-Score': f1,\n","            'Specificity': specificity,\n","            'Accuracy': val_accuracy\n","        })\n","\n","    # Convert results to a DataFrame\n","    results_df = pd.DataFrame(results)\n","    return results_df\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6Ajs2D1gS82B"},"outputs":[],"source":["def plot_reconstruction_error_with_shuffle(\n","    model,\n","    X_test_features_scaled,\n","    Y_test_labels,\n","    optimal_thresholds,\n","    percentiles,\n","    save_folder=\"reconstruction_error_shuffled_plots\"\n","):\n","\n","    # Ensure the save folder exists\n","    os.makedirs(save_folder, exist_ok=True)\n","\n","    # Compute reconstruction errors for the test set\n","    test_predictions = model.predict(X_test_features_scaled)\n","    test_reconstruction_errors = np.mean(np.square(X_test_features_scaled - test_predictions), axis=1)\n","\n","    # Shuffle the data indices\n","    shuffled_indices = np.random.permutation(len(Y_test_labels))\n","    shuffled_labels = Y_test_labels[shuffled_indices]\n","    shuffled_reconstruction_errors = test_reconstruction_errors[shuffled_indices]\n","\n","    # Plot for each threshold\n","    for idx, (threshold, percentile) in enumerate(zip(optimal_thresholds, percentiles)):\n","        # Apply threshold to classify test samples\n","        y_test_pred = (shuffled_reconstruction_errors > threshold).astype(int)\n","\n","        # Categorize points based on true/false positives/negatives\n","        true_anomalies = (shuffled_labels == 1) & (y_test_pred == 1)\n","        false_anomalies = (shuffled_labels == 0) & (y_test_pred == 1)\n","        true_normals = (shuffled_labels == 0) & (y_test_pred == 0)\n","        false_normals = (shuffled_labels == 1) & (y_test_pred == 0)\n","\n","        # Plot reconstruction errors with different colors\n","        plt.figure(figsize=(12, 6))\n","        plt.scatter(np.arange(len(shuffled_labels))[true_anomalies], shuffled_reconstruction_errors[true_anomalies], color='purple', label='True Anomaly', s=10)\n","        plt.scatter(np.arange(len(shuffled_labels))[false_anomalies], shuffled_reconstruction_errors[false_anomalies], color='red', label='False Anomaly', s=10)\n","        plt.scatter(np.arange(len(shuffled_labels))[true_normals], shuffled_reconstruction_errors[true_normals], color='blue', label='True Normal', s=10)\n","        plt.scatter(np.arange(len(shuffled_labels))[false_normals], shuffled_reconstruction_errors[false_normals], color='yellow', label='False Normal', s=10)\n","\n","        # Add plot details\n","        plt.axhline(y=threshold, color='green', linestyle='--', label=f'Threshold: {threshold:.2f}')\n","        plt.title(f\"Plot for reconstruction error\")\n","        plt.xlabel(\"Data Index\")\n","        plt.ylabel(\"Reconstruction Error\")\n","        plt.legend()\n","        plt.tight_layout()\n","\n","        # Save the figure as an image\n","        image_path = os.path.join(save_folder, f\"reconstruction_error_percentile_{percentile}_shuffled.png\")\n","        plt.savefig(image_path, bbox_inches='tight')\n","\n","        # Display the figure\n","        plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U3xpIDpAS82C"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"_EP8usSWS82D"},"outputs":[],"source":["#Function to detect anomalies on new data using the model and threshold\n","def detect_anomalies_1(model_1, data_1, threshold_1):\n","    nn_input_data_1 =data_1\n","    predictions_1 = model_1.predict(nn_input_data_1)\n","    reconstruction_errors_1 = np.mean(np.square(nn_input_data_1 - predictions_1), axis=1)\n","    anomalies_1 = np.where(reconstruction_errors_1 > threshold_1, 1, 0)\n","    return anomalies_1"]},{"cell_type":"markdown","metadata":{"id":"UpSPL1ulS82E"},"source":["Temporal analysis of movements and detections Functions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IEpZc9miS82F"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_HwPqoc-S82G"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UKs90E8dS82H"},"outputs":[],"source":["def plot_movement_with_anomalies_only(data, test_data, specific_fishid, start_date, end_date, model_name, anomaly_column, prediction_column):\n","\n","    # Convert datetime columns to datetime type\n","    data['datetime'] = pd.to_datetime(data['datetime'])\n","    test_data['datetime'] = pd.to_datetime(test_data['datetime'])\n","\n","    # Filter data within the specified date range\n","    filtered_data = data[(data['datetime'] >= start_date) & (data['datetime'] <= end_date)]\n","    filtered_test_data = test_data[(test_data['datetime'] >= start_date) & (test_data['datetime'] <= end_date)]\n","\n","    # Filter specific fish ID\n","    all_movements = filtered_data[filtered_data['fishid'] == specific_fishid]\n","    filtered_test_data = filtered_test_data[filtered_test_data['fishid'] == specific_fishid]\n","\n","    # Classify the results\n","    true_positives = filtered_test_data[(filtered_test_data[anomaly_column] == 1) & (filtered_test_data[prediction_column] == 1)]\n","    false_positives = filtered_test_data[(filtered_test_data[anomaly_column] == 0) & (filtered_test_data[prediction_column] == 1)]\n","    false_negatives = filtered_test_data[(filtered_test_data[anomaly_column] == 1) & (filtered_test_data[prediction_column] == 0)]\n","\n","    # Convert datetime to matplotlib format\n","    def to_mdates(series):\n","        return mdates.date2num(series)\n","\n","    # Plotting\n","    plt.figure(figsize=(15, 6))\n","\n","    # Plot all movements for context\n","    plt.plot_date(to_mdates(all_movements['datetime']), all_movements['lat'], 'b-', alpha=0.5, label='Fish Movement')\n","\n","    # Plot false positives\n","    plt.plot_date(to_mdates(false_positives['datetime']), false_positives['lat'], 'ro', label='False Positives')\n","\n","    # Plot false negatives\n","    plt.plot_date(to_mdates(false_negatives['datetime']), false_negatives['lat'], 'go', label='False Negatives')\n","\n","    # Plot true positives\n","    plt.plot_date(to_mdates(true_positives['datetime']), true_positives['lat'], 'yo', label='True Positives')\n","\n","    # Add title and labels\n","    plt.title(f'{model_name}: Fish Movement and Anomalies for FishID {specific_fishid}')\n","    plt.xlabel('Date')\n","    plt.ylabel('Latitude')\n","\n","    # Show legend\n","    plt.legend()\n","\n","    # Format x-axis\n","    plt.gca().xaxis.set_major_locator(mdates.AutoDateLocator())\n","    plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n","    plt.gcf().autofmt_xdate()\n","\n","    # Rotate x-axis labels for better readability\n","    plt.xticks(rotation=45)\n","\n","    # Adjust layout\n","    plt.tight_layout()\n","\n","    # Display the plot\n","    plt.show()"]},{"cell_type":"markdown","metadata":{"id":"NqFse6ELS82I"},"source":["Generating acoustic telemetry data from real data(Fish detection fuctions)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zMmvkC_1S82I"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FQgltOnlS82J"},"outputs":[],"source":["def augment_data_with_sampling(normal_data, median_sampling_rate_seconds=8):\n","    # Ensure the data is sorted by datetime\n","    data1 = normal_data.copy()\n","    data1['datetime'] = pd.to_datetime(data1['datetime'])\n","    data1 = data1.sort_values('datetime').reset_index(drop=True)\n","\n","    # Create a copy of the original data to modify it in place\n","    augmented_data = data1.copy()\n","\n","    # Iterate through the dataset and add new instances where needed\n","    i = 0\n","    while i < len(augmented_data) - 1:\n","        current_time = augmented_data.loc[i, 'datetime']\n","        next_time = augmented_data.loc[i + 1, 'datetime']\n","        time_diff = next_time - current_time\n","\n","        if time_diff > pd.Timedelta(seconds=median_sampling_rate_seconds):\n","            samples_needed = int(time_diff.total_seconds() // median_sampling_rate_seconds)\n","            sampled_row = augmented_data.sample(n=1, replace=True, random_state=42).iloc[0].copy()\n","\n","            for j in range(1, samples_needed + 1):\n","                new_time = current_time + pd.to_timedelta(j * median_sampling_rate_seconds, unit='s')\n","                if new_time >= next_time:\n","                    break\n","                new_row = sampled_row.copy()\n","                new_row['datetime'] = new_time\n","                augmented_data = pd.concat([\n","                    augmented_data.iloc[:i + 1],\n","                    pd.DataFrame([new_row]),\n","                    augmented_data.iloc[i + 1:]\n","                ]).reset_index(drop=True)\n","                i += 1\n","\n","                # Re-evaluate the next interval after insertion\n","                current_time = new_time\n","                next_time = augmented_data.loc[i + 1, 'datetime']\n","                time_diff = next_time - current_time\n","\n","                if time_diff <= pd.Timedelta(seconds=median_sampling_rate_seconds):\n","                    break\n","\n","        i += 1\n","\n","    # Drop any potential duplicates\n","    augmented_data = augmented_data.drop_duplicates(subset=['datetime']).reset_index(drop=True)\n","\n","    return augmented_data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xjVJi9zoS82J"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"LCUPP3sYS82J"},"source":["# Loading data and models\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"K1TYav-DS82L"},"outputs":[],"source":["#Test data for shallow models\n","training_data1=pd.concat([train_data_final, validation_data])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P8VHHH6_S82M"},"outputs":[],"source":["def prepare_datasets_from_precomputed(train_data_final, test_data, validation_data, anomaly_column='Anomaly'):\n","    # Separate features and target variables\n","    columns_to_drop = [anomaly_column, 'fishid','datetime', 'tag_date', 'station', 'date', 'avg_time_between_detections',\n","                   'time_since_last_detection', 'time_since_last_detection_days'] # Drop 'fishid' and 'datetime'\n","    X_train_features = train_data_final.drop(columns=columns_to_drop).values\n","    Y_train_labels = train_data_final[anomaly_column].values\n","    X_test_features = test_data.drop(columns=columns_to_drop).values\n","    Y_test_labels = test_data[anomaly_column].values\n","\n","    # Separate anomalies and normal data in validation data\n","    anomalies = validation_data[validation_data[anomaly_column] == 1]\n","    normal = validation_data[validation_data[anomaly_column] == 0]\n","\n","    # Split normal data in validation set into two subsets\n","    normal_subset_1, normal_subset_2 = train_test_split(normal, test_size=0.5)\n","\n","    # Create two balanced validation sets\n","    validation_set_1 = normal_subset_1\n","    validation_set_2 = pd.concat([anomalies, normal_subset_2])\n","\n","    # Separate features and labels for validation sets\n","    X_validation_set_1_features = validation_set_1.drop(columns=columns_to_drop).values\n","    Y_validation_set_1_labels = validation_set_1[anomaly_column].values\n","    X_validation_set_2_features = validation_set_2.drop(columns=columns_to_drop).values\n","    Y_validation_set_2_labels = validation_set_2[anomaly_column].values\n","\n","    # Scale feature values\n","    scaler = MinMaxScaler(feature_range=(0, 1))\n","    X_train_features_scaled = scaler.fit_transform(X_train_features)\n","    X_test_features_scaled = scaler.transform(X_test_features)\n","    X_validation_set_1_features_scaled = scaler.transform(X_validation_set_1_features)\n","    X_validation_set_2_features_scaled = scaler.transform(X_validation_set_2_features)\n","\n","    # Return all datasets as variables, including the full test_data\n","    return {\n","        \"X_train_features_scaled\": X_train_features_scaled,\n","        \"X_test_features_scaled\": X_test_features_scaled,\n","        \"X_validation_set_1_features_scaled\": X_validation_set_1_features_scaled,\n","        \"X_validation_set_2_features_scaled\": X_validation_set_2_features_scaled,\n","        \"Y_train_labels\": Y_train_labels,\n","        \"Y_test_labels\": Y_test_labels,\n","        \"Y_validation_set_1_labels\": Y_validation_set_1_labels,\n","        \"Y_validation_set_2_labels\": Y_validation_set_2_labels,\n","        \"X_test_features\": X_test_features,\n","        \"test_data\": test_data\n","    }\n","\n","variables = prepare_datasets_from_precomputed(train_data_final, test_data, validation_data)\n","\n","# Access variables\n","X_train_features_scaled = variables[\"X_train_features_scaled\"]\n","X_test_features_scaled = variables[\"X_test_features_scaled\"]\n","X_validation_set_1_features_scaled = variables[\"X_validation_set_1_features_scaled\"]\n","X_validation_set_2_features_scaled = variables[\"X_validation_set_2_features_scaled\"]\n","Y_train_labels = variables[\"Y_train_labels\"]\n","Y_test_labels = variables[\"Y_test_labels\"]\n","Y_validation_set_1_labels = variables[\"Y_validation_set_1_labels\"]\n","Y_validation_set_2_labels = variables[\"Y_validation_set_2_labels\"]"]},{"cell_type":"markdown","metadata":{"id":"WQ2sY3FqS82M"},"source":["# Building and Fitting the model"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7xoLG8UJS82M"},"outputs":[],"source":["# Looking for optimal threshold for each percentile\n","results_df = calculate_metrics_for_multiple_percentiles(\n","    model=model,\n","    X_train_features_scaled=X_train_features_scaled,\n","    Y_train_labels=Y_train_labels,\n","    X_test_features_scaled=X_test_features_scaled,\n","    Y_test_labels=Y_test_labels,\n","    X_validation_set_2_features_scaled=X_validation_set_2_features_scaled,\n","    Y_validation_set_2_labels=Y_validation_set_2_labels\n",")\n","\n","# Display the results dataframe\n","print(results_df)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DMN72QfdS82N"},"outputs":[],"source":["# Create a figure and axis to plot the dataframe\n","fig, ax = plt.subplots(figsize=(8, 6))  # Adjust the size if needed\n","ax.axis('tight')\n","ax.axis('off')\n","\n","# Render the dataframe as a table on the plot\n","ax.table(cellText=results_df.values, colLabels=results_df.columns, cellLoc='center', loc='center')\n","\n","# Save the plot as a PDF\n","with PdfPages('results_df_Big_new.pdf') as pdf:\n","    pdf.savefig(fig, bbox_inches='tight')\n","    plt.close(fig)\n","\n","print(\"DataFrame has been saved as PDF.\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"WoAmwRGmS82N"},"outputs":[],"source":["#Looking for optimal threshold for each percentile\n","results_df = calculate_metrics_for_multiple_percentiles(\n","    model=model,\n","    X_train_features_scaled=X_train_features_scaled,\n","    Y_train_labels=Y_train_labels,\n","    X_test_features_scaled=X_test_features_scaled,\n","    Y_test_labels=Y_test_labels,\n","    X_validation_set_2_features_scaled=X_validation_set_2_features_scaled,\n","    Y_validation_set_2_labels=Y_validation_set_2_labels\n",")\n","print(results_df)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OEXJpNoDS82N"},"outputs":[],"source":["# Extract the metrics you need\n","percentiles = results_df['Percentile'].values\n","precision = results_df['Precision'].values\n","recall = results_df['Recall'].values\n","specificity = results_df['Specificity'].values\n","\n","# Display the extracted metrics\n","print(\"Percentiles:\", percentiles)\n","print(\"Precision:\", precision)\n","print(\"Recall:\", recall)\n","print(\"Specificity:\", specificity)"]},{"cell_type":"code","source":["def plot_reconstruction_error_with_multiple_thresholds(\n","    model,\n","    X_validation_set_2_features_scaled,\n","    Y_validation_set_2_labels_scaled,\n","    optimal_thresholds,\n","    percentiles,\n","    #additional_thresholds,  # List of additional thresholds to display on each plot\n","    save_folder=\"reconstruction_error_shuffled_plots\"\n","):\n","\n","    # Ensure the save folder exists\n","    os.makedirs(save_folder, exist_ok=True)\n","\n","    # Compute reconstruction errors for the test set\n","    test_predictions = model.predict(X_validation_set_2_features_scaled)\n","    test_reconstruction_errors = np.mean(np.square(X_validation_set_2_features_scaled - test_predictions), axis=1)\n","\n","    # Shuffle the data indices\n","    shuffled_indices = np.random.permutation(len(Y_validation_set_2_labels_scaled))\n","    shuffled_labels = Y_validation_set_2_labels_scaled[shuffled_indices]\n","    shuffled_reconstruction_errors = test_reconstruction_errors[shuffled_indices]\n","\n","    # Plot for each threshold\n","    for idx, (threshold, percentile) in enumerate(zip(optimal_thresholds, percentiles)):\n","        # Apply the main threshold to classify test samples\n","        y_test_pred = (shuffled_reconstruction_errors > threshold).astype(int)\n","\n","        # Categorize points based on true/false positives/negatives\n","        true_anomalies = (shuffled_labels == 1) & (y_test_pred == 1)\n","        false_anomalies = (shuffled_labels == 0) & (y_test_pred == 1)\n","        true_normals = (shuffled_labels == 0) & (y_test_pred == 0)\n","        false_normals = (shuffled_labels == 1) & (y_test_pred == 0)\n","\n","        # Plot reconstruction errors with different colors\n","        plt.figure(figsize=(6, 5))\n","        plt.scatter(np.arange(len(shuffled_labels))[true_anomalies]/1000, shuffled_reconstruction_errors[true_anomalies], color='purple', label='True Anomaly', s=10)\n","        plt.scatter(np.arange(len(shuffled_labels))[false_anomalies]/1000, shuffled_reconstruction_errors[false_anomalies], color='red', label='False Anomaly', s=10)\n","        plt.scatter(np.arange(len(shuffled_labels))[true_normals]/1000, shuffled_reconstruction_errors[true_normals], color='blue', label='True Normal', s=10)\n","        plt.scatter(np.arange(len(shuffled_labels))[false_normals]/1000, shuffled_reconstruction_errors[false_normals], color='yellow', label='False Normal', s=10)\n","\n","        # Add horizontal lines for each threshold\n","        plt.axhline(y=threshold, color='green', linestyle='--', label=f'Threshold: {threshold:.2f}')\n","\n","        # Add plot details\n","        plt.xlabel(r\"Data Index [$\\times 10^3$]\",fontsize=8)\n","        plt.ylabel(\"Reconstruction Error\",fontsize=8)\n","        plt.legend(loc=\"best\",fontsize=\"8\")\n","        plt.tight_layout()\n","\n","        # Save the figure as an image\n","        image_path = os.path.join(save_folder, f\"reconstruction_error_percentile_{percentile}_shuffled.png\")\n","        plt.savefig(image_path, bbox_inches='tight')\n","\n","        # Display the figure\n","        plt.show()"],"metadata":{"id":"WlF4L8uO5P7X"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"44_904afS82N"},"outputs":[],"source":["\n","\n","\n","\n","optimal_thresholds = results_df['Optimal Threshold'].tolist()\n","percentiles = results_df['Percentile'].tolist()\n","\n","# Call the function\n","plot_reconstruction_error_with_multiple_thresholds(\n","    model,\n","    X_validation_set_2_features_scaled,\n","    Y_validation_set_2_labels,\n","    optimal_thresholds,\n","    percentiles\n",")"]},{"cell_type":"markdown","metadata":{"id":"uXcjCCsSS82O"},"source":["# NN_AE Plots"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7G6Q0mBtS82O"},"outputs":[],"source":["best_threshold_original = 0.120692\n","# Detect anomalies in the test data\n","anomalies_test_data = detect_anomalies_1(model, X_test_features_scaled, best_threshold_original)\n","\n","# Prepare processed test data with 'datetime' and 'fishid'\n","processed_test_data = pd.DataFrame(variables[\"X_test_features_scaled\"])\n","processed_test_data['Anomaly'] = variables[\"Y_test_labels\"]\n","processed_test_data['Anomaly_Predicted'] = anomalies_test_data\n","\n","# Add the datetime column back to processed_test_data\n","processed_test_data['datetime'] = variables[\"test_data\"]['datetime']\n","processed_test_data['lat'] = variables[\"test_data\"]['lat']\n","processed_test_data['fishid'] = variables[\"test_data\"]['fishid']\n","\n","# Evaluation metrics\n","y_true = processed_test_data['Anomaly']\n","y_pred = processed_test_data['Anomaly_Predicted']\n","\n","accuracy = accuracy_score(y_true, y_pred)\n","precision = precision_score(y_true, y_pred, zero_division=1)\n","recall = recall_score(y_true, y_pred, zero_division=1)\n","f1 = f1_score(y_true, y_pred, zero_division=1)\n","roc_auc = roc_auc_score(y_true, y_pred) if len(np.unique(y_true)) > 1 else None\n","\n","# Confusion matrix\n","conf_matrix = confusion_matrix(y_true, y_pred)\n","tn, fp, fn, tp = conf_matrix.ravel()\n","\n","# Specificity calculation\n","specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n","\n","# Print the evaluation metrics\n","print(\"Model Evaluation Metrics on Test Data:\")\n","print(\"Accuracy:\", accuracy)\n","print(\"Precision:\", precision)\n","print(\"Recall:\", recall)\n","print(\"F1-score:\", f1)\n","print(\"Specificity:\", specificity)\n","if roc_auc is not None:\n","    print(\"ROC AUC:\", roc_auc)\n","else:\n","    print(\"ROC AUC is not applicable. Only one class present in y_true.\")"]},{"cell_type":"code","source":["def plot_movement_with_anomalies(data, test_data, start_date, end_date, model_name, anomaly_column, prediction_column):\n","\n","    # Convert datetime columns to datetime type\n","    data['datetime'] = pd.to_datetime(data['datetime'])\n","    test_data['datetime'] = pd.to_datetime(test_data['datetime'])\n","\n","    # Filter data within the specified date range\n","    filtered_data = data[(data['datetime'] >= start_date) & (data['datetime'] <= end_date)]\n","    filtered_test_data = test_data[(test_data['datetime'] >= start_date) & (test_data['datetime'] <= end_date)]\n","\n","    # Classify the results\n","    true_positives = filtered_test_data[(filtered_test_data[anomaly_column] == 1) & (filtered_test_data[prediction_column] == 1)]\n","    true_negatives = filtered_test_data[(filtered_test_data[anomaly_column] == 0) & (filtered_test_data[prediction_column] == 0)]\n","    false_positives = filtered_test_data[(filtered_test_data[anomaly_column] == 0) & (filtered_test_data[prediction_column] == 1)]\n","    false_negatives = filtered_test_data[(filtered_test_data[anomaly_column] == 1) & (filtered_test_data[prediction_column] == 0)]\n","\n","    anomalies = filtered_test_data[filtered_test_data[anomaly_column] == 1]\n","\n","    # Helper function to plot\n","    def plot_helper(title, highlight_data, highlight_label, highlight_style, color):\n","        plt.figure(figsize=(12, 4))\n","        plt.plot(filtered_data['datetime'], filtered_data['lat'], 'b-', alpha=0.3, label='Fish Movement')\n","        plt.plot(anomalies['datetime'], anomalies['lat'], 'ro', label='Anomalies')\n","        plt.plot(highlight_data['datetime'], highlight_data['lat'], highlight_style, color=color, label=highlight_label)\n","\n","        plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n","        plt.gcf().autofmt_xdate()\n","        plt.title(f'{title} ({model_name})', fontsize=16)\n","        plt.xlabel('Date')\n","        plt.ylabel('Latitude', fontsize=16)\n","        plt.xticks(fontsize=12, rotation=45)\n","        plt.yticks(fontsize=12)\n","        plt.legend(loc='upper right', fontsize=16)\n","        plt.show()\n","\n","    # Plotting different cases\n","    plot_helper('Fish Movement and True Anomalies Highlighted', true_positives, 'True Anomalies', 'x', 'm')\n","    plot_helper('Fish Movement and True Normals Highlighted', true_negatives, 'True Normals', '^', 'g')\n","    plot_helper('Fish Movement and False Anomalies Highlighted', false_positives, 'False Anomalies', 'x', 'y')\n","    plot_helper('Fish Movement and False Normals Highlighted', false_negatives, 'False Normals', '^', 'c')"],"metadata":{"id":"Kip6ohUrnL5v"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5wekIfuwS82O"},"outputs":[],"source":["plot_movement_with_anomalies(\n","    data=data,\n","    test_data=processed_test_data,\n","    start_date='2016-01-01',\n","    end_date='2021-12-31',\n","    model_name='NN-AE',\n","    anomaly_column='Anomaly',\n","    prediction_column='Anomaly_Predicted'\n",")"]},{"cell_type":"code","source":["def plot_movement_with_anomalies2020(data, test_data, start_date, end_date, model_name, anomaly_column, prediction_column):\n","\n","    # Convert datetime columns to datetime type\n","    data['datetime'] = pd.to_datetime(data['datetime'])\n","    test_data['datetime'] = pd.to_datetime(test_data['datetime'])\n","\n","    # Filter data within the specified date range\n","    filtered_data = data[(data['datetime'] >= start_date) & (data['datetime'] <= end_date)]\n","    filtered_test_data = test_data[(test_data['datetime'] >= start_date) & (test_data['datetime'] <= end_date)]\n","\n","    # Classify the results\n","    true_positives = filtered_test_data[(filtered_test_data[anomaly_column] == 1) & (filtered_test_data[prediction_column] == 1)]\n","    true_negatives = filtered_test_data[(filtered_test_data[anomaly_column] == 0) & (filtered_test_data[prediction_column] == 0)]\n","    false_positives = filtered_test_data[(filtered_test_data[anomaly_column] == 0) & (filtered_test_data[prediction_column] == 1)]\n","    false_negatives = filtered_test_data[(filtered_test_data[anomaly_column] == 1) & (filtered_test_data[prediction_column] == 0)]\n","\n","    anomalies = filtered_test_data[filtered_test_data[anomaly_column] == 1]\n","\n","    #function to plot\n","    def plot_helper(title, highlight_data, highlight_label, highlight_style, color):\n","        plt.figure(figsize=(12, 4))\n","        plt.plot(filtered_data['datetime'], filtered_data['lat'], 'b-', alpha=0.3, label='Fish Movement')\n","        plt.plot(anomalies['datetime'], anomalies['lat'], 'ro', label='Anomalies')\n","        plt.plot(highlight_data['datetime'], highlight_data['lat'], highlight_style, color=color, label=highlight_label)\n","\n","        plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n","        plt.gcf().autofmt_xdate()\n","        #plt.title(f'{title} ({model_name}) -2020',fontsize=16)\n","        plt.ylabel('Latitude',fontsize=16)\n","        plt.xticks(fontsize=12, rotation=45)\n","        plt.yticks(fontsize=12)\n","        #plt.legend(loc='best', fontsize=16)\n","        plt.show()\n","\n","    # Plotting different cases\n","    plot_helper('Fish Movement and True Anomalies Highlighted', true_positives, 'True Anomalies', 'x', 'm')\n","    plot_helper('Fish Movement and True Normals Highlighted', true_negatives, 'True Normals', '^', 'g')\n","    plot_helper('Fish Movement and False Anomalies Highlighted', false_positives, 'False Anomalies', 'x', 'y')\n","    plot_helper('Fish Movement and False Normals Highlighted', false_negatives, 'False Normals', '^', 'c')"],"metadata":{"id":"KqgWzDQwr6Bt"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yVYpydlHS82O"},"outputs":[],"source":["plot_movement_with_anomalies2020(\n","    data=data,\n","    test_data=processed_test_data,\n","    start_date='2020-01-01',\n","    end_date='2020-12-31',\n","    model_name='NN_AE',\n","    anomaly_column='Anomaly',\n","    prediction_column='Anomaly_Predicted'\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6OvxJJajS82P"},"outputs":[],"source":["# Neural Network Autoencoder\n","plot_movement_with_anomalies_only(\n","    data=data,\n","    test_data=processed_test_data,\n","    start_date='2016-01-01',\n","    end_date='2021-12-31',\n","    specific_fishid= 'A69-9001-23859a',\n","    model_name='NN_AE',\n","    anomaly_column='Anomaly',\n","    prediction_column='Anomaly_Predicted'\n",")"]},{"cell_type":"markdown","metadata":{"id":"Z2G59MBkS82P"},"source":["# Isolation Forest Plots"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Vlp50_ZtS82P"},"outputs":[],"source":["# Feature selection for Isolation Forest\n","selected_features_IF_original = ['lat', 'lon', 'duration_in_same_station', 'num_detections', 'distance', 'num_days_detected', 'num_unique_stations', 'consecutive_missing_stations']\n","test_data_IF_original = test_data[selected_features_IF_original + ['datetime']]\n","\n","# Ground truth labels (actual anomalies) from the testing set\n","y_true_model_IF_original = test_data.loc[test_data_IF_original.index, 'Anomaly']\n","\n","# Predict anomalies using the loaded model\n","anomalies_IF_original = loaded_isolation_forest_IF_original.predict(test_data_IF_original.drop('datetime', axis=1))\n","anomalies_IF_original = anomalies_IF_original == -1  # Convert -1 to True for anomalies\n","\n","# Avoid SettingWithCopyWarning by creating a copy\n","test_data_IF_original = test_data.copy()\n","test_data_IF_original['Isolation_Forest_Anomaly'] = anomalies_IF_original.astype(int)\n","\n","# Model's predictions on the testing data using Isolation Forest\n","y_pred_model_IF_original = test_data_IF_original['Isolation_Forest_Anomaly']\n","\n","# Evaluate the performance of Isolation Forest\n","accuracy_IF_original = accuracy_score(y_true_model_IF_original, y_pred_model_IF_original)\n","precision_IF_original = precision_score(y_true_model_IF_original, y_pred_model_IF_original)\n","recall_IF_original = recall_score(y_true_model_IF_original, y_pred_model_IF_original)\n","f1_IF_original = f1_score(y_true_model_IF_original, y_pred_model_IF_original)\n","\n","# Confusion matrix\n","conf_matrix_IF_original = confusion_matrix(y_true_model_IF_original, y_pred_model_IF_original)\n","tn, fp, fn, tp = conf_matrix_IF_original.ravel()\n","\n","# Calculate specificity\n","specificity_IF_original = tn / (tn + fp)\n","\n","# Calculate AUC\n","# Ensure y_prob_model_IF_original contains anomaly scores or probabilities\n","auc_IF_original = roc_auc_score(y_true_model_IF_original, y_pred_model_IF_original)\n","\n","# Print performance metrics\n","print(\"Isolation Forest Performance with Best Parameters:\")\n","print(\"Accuracy:\", accuracy_IF_original)\n","print(\"Precision:\", precision_IF_original)\n","print(\"Recall:\", recall_IF_original)\n","print(\"F1-score:\", f1_IF_original)\n","print(\"Specificity:\", specificity_IF_original)\n","print(\"AUC:\", auc_IF_original)\n","\n","# Print confusion matrix\n","print(\"Confusion Matrix:\")\n","print(conf_matrix_IF_original)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5IiTq3MGS82P"},"outputs":[],"source":["plot_movement_with_anomalies(\n","    data=data,\n","    test_data=test_data_IF_original,\n","    start_date='2016-01-01',\n","    end_date='2021-12-31',\n","    model_name='IF',\n","    anomaly_column='Anomaly',\n","    prediction_column='Isolation_Forest_Anomaly'\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"w0cPkhz8S82Q"},"outputs":[],"source":["plot_movement_with_anomalies2020(\n","    data=data,\n","    test_data=test_data_IF_original,\n","    start_date='2020-01-01',\n","    end_date='2020-12-31',\n","    model_name='IF',\n","    anomaly_column='Anomaly',\n","    prediction_column='Isolation_Forest_Anomaly'\n",")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Eh8orlJlS82a"},"outputs":[],"source":["# Isolation Forest\n","plot_movement_with_anomalies_only(\n","    data=data,\n","    test_data=test_data_IF_original,\n","    start_date='2016-01-01',\n","    end_date='2021-12-31',\n","    specific_fishid= 'A69-9001-23859a',\n","    model_name='IF',\n","    anomaly_column='Anomaly',\n","    prediction_column='Isolation_Forest_Anomaly'\n",")"]},{"cell_type":"markdown","metadata":{"id":"kgjI6do6S82a"},"source":["# DBSCAN Plots"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"65snXhGMS82a"},"outputs":[],"source":["# Ground truth labels (actual anomalies) from the testing set\n","y_true_DBSCAN_Original = test_data['Anomaly']\n","\n","# Feature selection for DBSCAN\n","selected_features_DBSCAN_Original = [\n","    'receiver', 'lat', 'lon', 'duration_in_same_station', 'num_detections',\n","    'distance', 'num_days_detected', 'num_unique_stations', 'consecutive_missing_stations'\n","]\n","\n","X_test_DBSCAN_Original = test_data[selected_features_DBSCAN_Original]\n","\n","# Use the best parameters to detect anomalies\n","dbscan_best = DBSCAN(eps=0.5, min_samples=10)\n","clusters_best = dbscan_best.fit_predict(X_test_DBSCAN_Original)\n","anomalies_DBSCAN_Original = (clusters_best == -1)  # Mark clusters labeled -1 as anomalies\n","test_data_DBSCAN_Original = test_data.copy()\n","\n","# Create a binary label for DBSCAN-detected anomalies (1: anomaly, 0: normal)\n","test_data_DBSCAN_Original['DBSCAN_Anomaly'] = anomalies_DBSCAN_Original.astype(int)\n","\n","# Model's predictions on the testing data using DBSCAN\n","y_pred_DBSCAN_Original = test_data_DBSCAN_Original['DBSCAN_Anomaly']\n","\n","# Evaluate the performance of DBSCAN\n","accuracy_DBSCAN_Original = accuracy_score(y_true_DBSCAN_Original, y_pred_DBSCAN_Original)\n","precision_DBSCAN_Original = precision_score(y_true_DBSCAN_Original, y_pred_DBSCAN_Original)\n","recall_DBSCAN_Original = recall_score(y_true_DBSCAN_Original, y_pred_DBSCAN_Original)\n","f1_DBSCAN_Original = f1_score(y_true_DBSCAN_Original, y_pred_DBSCAN_Original)\n","\n","# Confusion matrix\n","conf_matrix_DBSCAN_Original = confusion_matrix(y_true_DBSCAN_Original, y_pred_DBSCAN_Original)\n","print(\"Confusion Matrix:\")\n","print(conf_matrix_DBSCAN_Original)\n","\n","# Calculate specificity\n","tn, fp, fn, tp = conf_matrix_DBSCAN_Original.ravel()\n","specificity_DBSCAN_Original = tn / (tn + fp)\n","\n","# Calculate AUC\n","auc_DBSCAN_Original = roc_auc_score(y_true_DBSCAN_Original, y_pred_DBSCAN_Original)\n","\n","# Print DBSCAN performance metrics\n","print(\"DBSCAN Performance:\")\n","print(\"Accuracy:\", accuracy_DBSCAN_Original)\n","print(\"Precision:\", precision_DBSCAN_Original)\n","print(\"Recall:\", recall_DBSCAN_Original)\n","print(\"F1-score:\", f1_DBSCAN_Original)\n","print(\"Specificity:\", specificity_DBSCAN_Original)\n","print(\"AUC:\", auc_DBSCAN_Original)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ULneXWcDS82b"},"outputs":[],"source":["plot_movement_with_anomalies(\n","    data=data,\n","    test_data=test_data_DBSCAN_Original,\n","    start_date='2016-01-01',\n","    end_date='2021-12-31',\n","    model_name='DBSCAN',\n","    anomaly_column='Anomaly',\n","    prediction_column='DBSCAN_Anomaly'\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"V2LXMCSiS82b"},"outputs":[],"source":["plot_movement_with_anomalies2020(\n","    data=data,\n","    test_data=test_data_DBSCAN_Original,\n","    start_date='2020-01-01',\n","    end_date='2020-12-31',\n","    model_name='DBSCAN',\n","    anomaly_column='Anomaly',\n","    prediction_column='DBSCAN_Anomaly'\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AkYBuGhOS82b"},"outputs":[],"source":["# DBSCAN\n","plot_movement_with_anomalies_only(\n","    data=data,\n","    test_data=test_data_DBSCAN_Original,\n","    start_date='2016-01-01',\n","    end_date='2021-12-31',\n","    specific_fishid= 'A69-9001-23859a',\n","    model_name='DBSCAN',\n","    anomaly_column='Anomaly',\n","    prediction_column='DBSCAN_Anomaly'\n",")"]},{"cell_type":"markdown","metadata":{"id":"hT1oFp1oS82c"},"source":["# LOF Plots"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"siaIY91DS82c"},"outputs":[],"source":["# Ground truth labels (actual anomalies) from the testing set\n","y_true_LOF_original = test_data['Anomaly']\n","\n","# Feature selection for LOF\n","selected_features_LOF_original = ['receiver', 'lat', 'lon', 'duration_in_same_station', 'num_detections',\n","                                  'distance', 'num_days_detected', 'num_unique_stations', 'consecutive_missing_stations']\n","\n","X_train_LOF_original = training_data1[selected_features_LOF_original]\n","X_test_LOF_original = test_data[selected_features_LOF_original]\n","\n","# Use the best parameters to create the LOF model\n","lof_best = LocalOutlierFactor(n_neighbors=loaded_best_params_LOF_Original['n_neighbors'],\n","\n","                              contamination=loaded_best_params_LOF_Original['contamination'])\n","\n","# Predict anomalies with LOF\n","anomalies_best = lof_best.fit_predict(X_test_LOF_original)\n","anomalies_LOF_original = (anomalies_best == -1)  # Mark LOF detected anomalies (outliers) as 1\n","\n","# Create test_data_LOF_original similar to test_data_5\n","test_data_LOF_original = test_data.copy()  # Copy original test data\n","test_data_LOF_original['LOF_Anomaly'] = anomalies_LOF_original.astype(int)  # Add LOF anomalies as a new column\n","\n","# Model's predictions on the testing data using LOF\n","y_pred_LOF_original = test_data_LOF_original['LOF_Anomaly']\n","\n","# Evaluate the performance of LOF\n","accuracy_LOF_original = accuracy_score(y_true_LOF_original, y_pred_LOF_original)\n","precision_LOF_original = precision_score(y_true_LOF_original, y_pred_LOF_original)\n","recall_LOF_original = recall_score(y_true_LOF_original, y_pred_LOF_original)\n","f1_LOF_original = f1_score(y_true_LOF_original, y_pred_LOF_original)\n","\n","# Confusion matrix\n","conf_matrix_LOF_original = confusion_matrix(y_true_LOF_original, y_pred_LOF_original)\n","print(\"Confusion Matrix:\")\n","print(conf_matrix_LOF_original)\n","\n","# Calculate specificity\n","tn, fp, fn, tp = conf_matrix_LOF_original.ravel()\n","specificity_LOF_original = tn / (tn + fp)\n","print(\"LOF Performance:\")\n","print(\"Accuracy:\", accuracy_LOF_original)\n","print(\"Precision:\", precision_LOF_original)\n","print(\"Recall:\", recall_LOF_original)\n","print(\"F1-score:\", f1_LOF_original)\n","print(\"Specificity:\", specificity_LOF_original)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QH39dm4VS82c"},"outputs":[],"source":["plot_movement_with_anomalies(\n","    data=data,\n","    test_data=test_data_LOF_original,\n","    start_date='2016-01-01',\n","    end_date='2021-12-31',\n","    model_name='LOF',\n","    anomaly_column='Anomaly',\n","    prediction_column='LOF_Anomaly'\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"B4OQhGx0S82d"},"outputs":[],"source":["plot_movement_with_anomalies2020(\n","    data=data,\n","    test_data=test_data_LOF_original,\n","    start_date='2020-01-01',\n","    end_date='2020-12-31',\n","    model_name='LOF',\n","    anomaly_column='Anomaly',\n","    prediction_column='LOF_Anomaly'\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5GZfccszS82d"},"outputs":[],"source":["# Local Outlier Factor (LOF)\n","plot_movement_with_anomalies_only(\n","    data=data,\n","    test_data=test_data_LOF_original,\n","    start_date='2016-01-01',\n","    end_date='2021-12-31',\n","    specific_fishid= 'A69-9001-23859a',\n","    model_name='LOF',\n","    anomaly_column='Anomaly',\n","    prediction_column='LOF_Anomaly'\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_jSjFcFKS82d"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HhpHaE9xS82d"},"outputs":[],"source":["# Define confusion matrices\n","conf_matrix_isolation_Forest = np.array([[274996, 0], [131843, 142]])\n","conf_matrix_DBSCAN = np.array([[268314, 6682], [131656, 329]])\n","conf_matrix_Local_Outlier_Factor = np.array([[271462, 3534], [131449, 536]])\n","conf_matrix_NN_AE = np.array([[274031, 965], [0, 131985]])\n","\n","# Define additional confusion matrices with _90 and _65\n","conf_matrix_isolation_Forest_90 = np.array([[274996, 0], [131784, 201]])\n","conf_matrix_DBSCAN_90 = np.array([[268314, 6682], [131656, 329]])\n","conf_matrix_Local_Outlier_Factor_90 = np.array([[271462, 3534], [131449, 536]])\n","conf_matrix_NN_AE_90 = np.array([[274077, 919], [0, 131985]])\n","\n","conf_matrix_isolation_Forest_65 = np.array([[274996, 0], [131764, 221]])\n","conf_matrix_DBSCAN_65 = np.array([[268314, 6682], [131656, 329]])\n","conf_matrix_Local_Outlier_Factor_65 = np.array([[271462, 3534], [131449, 536]])\n","conf_matrix_NN_AE_65 = np.array([[274394, 602], [0, 131985]])\n","\n","# Function to calculate metrics from confusion matrix\n","def calculate_metrics(conf_matrix):\n","    TN, FP, FN, TP = conf_matrix.ravel()\n","    TPR = TP / (TP + FN) if (TP + FN) > 0 else 0  # True Positive Rate (Recall)\n","    TNR = TN / (TN + FP) if (TN + FP) > 0 else 0  # True Negative Rate\n","    FPR = FP / (FP + TN) if (FP + TN) > 0 else 0  # False Positive Rate\n","    FNR = FN / (TP + FN) if (TP + FN) > 0 else 0  # False Negative Rate\n","    return [TPR * 100, TNR * 100, FPR * 100, FNR * 100]  # List format\n","\n","# Calculate metrics for each model and for the new confusion matrices\n","metrics_NN_AE = calculate_metrics(conf_matrix_NN_AE)\n","metrics_isolation_Forest = calculate_metrics(conf_matrix_isolation_Forest)\n","metrics_DBSCAN = calculate_metrics(conf_matrix_DBSCAN)\n","metrics_Local_Outlier_Factor = calculate_metrics(conf_matrix_Local_Outlier_Factor)\n","\n","metrics_NN_AE_90 = calculate_metrics(conf_matrix_NN_AE_90)\n","metrics_isolation_Forest_90 = calculate_metrics(conf_matrix_isolation_Forest_90)\n","metrics_DBSCAN_90 = calculate_metrics(conf_matrix_DBSCAN_90)\n","metrics_Local_Outlier_Factor_90 = calculate_metrics(conf_matrix_Local_Outlier_Factor_90)\n","\n","metrics_NN_AE_65 = calculate_metrics(conf_matrix_NN_AE_65)\n","metrics_isolation_Forest_65 = calculate_metrics(conf_matrix_isolation_Forest_65)\n","metrics_DBSCAN_65 = calculate_metrics(conf_matrix_DBSCAN_65)\n","metrics_Local_Outlier_Factor_65 = calculate_metrics(conf_matrix_Local_Outlier_Factor_65)\n","\n","# Collect metrics in a dictionary\n","model_labels = ['NN-AE', 'IF', 'DBSCAN', 'LOF']\n","metrics_dict = {\n","    'NN-AE': [metrics_NN_AE, metrics_NN_AE_90, metrics_NN_AE_65],\n","    'IF': [metrics_isolation_Forest, metrics_isolation_Forest_90, metrics_isolation_Forest_65],\n","    'DBSCAN': [metrics_DBSCAN, metrics_DBSCAN_90, metrics_DBSCAN_65],\n","    'LOF': [metrics_Local_Outlier_Factor, metrics_Local_Outlier_Factor_90, metrics_Local_Outlier_Factor_65]\n","}\n","\n","# Define metric names and bar plot settings\n","metrics_names = ['True Anomaly Rate', 'True Normal Rate', 'False Anomaly Rate', 'False Normal Rate']\n","index = np.arange(len(metrics_names))\n","bar_width = 0.2\n","\n","\n","# Create a 3x1 grid of subplots (first two on top, third one at the bottom)\n","fig, axes = plt.subplots(3, 1, figsize=(18, 10))\n","\n","# Subplots: Bar plots for each subplot (first two on top, third one at the bottom)\n","for i, model in enumerate(model_labels):\n","    for j in range(2):  # Iterate over the first two confusion matrices (original, 90)\n","        metrics = metrics_dict[model][j]\n","        if j == 0:\n","            bars = axes[0].bar(index + i * bar_width - (bar_width * (len(model_labels) - 1)) / 2, metrics, bar_width, label=model)\n","        else:\n","            bars = axes[1].bar(index + i * bar_width - (bar_width * (len(model_labels) - 1)) / 2, metrics, bar_width, label=model)\n","\n","        # Add percentage labels on top of the bars\n","        for bar in bars:\n","            height = bar.get_height()\n","            if j == 0:\n","                axes[0].text(bar.get_x() + bar.get_width() / 2, height + 1, f'{height:.1f}', ha='center', va='bottom', fontsize=15)\n","            else:\n","                axes[1].text(bar.get_x() + bar.get_width() / 2, height + 1, f'{height:.1f}', ha='center', va='bottom', fontsize=15)\n","\n","# For the third subplot (bottom one), use the 65% confusion matrices\n","for i, model in enumerate(model_labels):\n","    metrics = metrics_dict[model][2]\n","    bars = axes[2].bar(index + i * bar_width - (bar_width * (len(model_labels) - 1)) / 2, metrics, bar_width, label=model)\n","\n","    # Add percentage labels on top of the bars\n","    for bar in bars:\n","        height = bar.get_height()\n","        axes[2].text(bar.get_x() + bar.get_width() / 2, height + 1, f'{height:.1f}', ha='center', va='bottom', fontsize=15)\n","\n","# Set common settings for all subplots\n","ii=0\n","for ax in axes.flat:\n","    if ii==0:\n","      ax.legend(loc='best', fontsize=20, bbox_to_anchor=(1.00, 0.5))  # Add legend to each subplot\n","      ii=ii+1\n","    ax.set_xticks(index)\n","    ax.set_xticklabels(metrics_names, fontsize=20)\n","    ax.set_ylabel('Percentage',fontsize=20)\n","    ax.set_ylim(0, 130)  # Set y-axis limit from 0 to 130\n","    ax.yaxis.set_tick_params(labelsize=15)\n","\n","\n","\n","# Set titles for each subplot\n","axes[0].set_title('Without resampling', fontsize=20)\n","axes[1].set_title('Resampling 90s', fontsize=20)\n","axes[2].set_title('Resampling 65s', fontsize=20)\n","\n","# Adjust layout\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ay2fZUqjS82e"},"outputs":[],"source":["#confusion matrices for each model\n","conf_matrix_NN_AE = confusion_matrix(y_true, y_pred)\n","conf_matrix_isolation_Forest = confusion_matrix(y_true_model_IF_original, y_pred_model_IF_original)\n","conf_matrix_DBSCAN = confusion_matrix(y_true_DBSCAN_Original, y_pred_DBSCAN_Original)\n","conf_matrix_Local_Outlier_Factor = confusion_matrix(y_true_LOF_original, y_pred_LOF_original)\n","\n","# Function to calculate metrics from confusion matrix\n","def calculate_metrics(conf_matrix):\n","    TN, FP, FN, TP = conf_matrix.ravel()\n","    TPR = TP / (TP + FN) if (TP + FN) > 0 else 0  # True Positive Rate (Recall)\n","    TNR = TN / (TN + FP) if (TN + FP) > 0 else 0  # True Negative Rate\n","    FPR = FP / (FP + TN) if (FP + TN) > 0 else 0  # False Positive Rate\n","    FNR = FN / (TP + FN) if (TP + FN) > 0 else 0  # False Negative Rate\n","    return TPR * 100, TNR * 100, FPR * 100, FNR * 100  # Convert to percentage\n","\n","# Calculate metrics for each model\n","metrics_NN_AE = calculate_metrics(conf_matrix_NN_AE)\n","metrics_isolation_Forest = calculate_metrics(conf_matrix_isolation_Forest)\n","metrics_DBSCAN = calculate_metrics(conf_matrix_DBSCAN)\n","metrics_Local_Outlier_Factor = calculate_metrics(conf_matrix_Local_Outlier_Factor)\n","\n","# Collect all metrics in the specified model order\n","model_labels = ['NN-AE', 'IF', 'DBSCAN', 'LOF']\n","metrics_dict = {\n","    'NN-AE': metrics_NN_AE,\n","    'IF': metrics_isolation_Forest,\n","    'DBSCAN': metrics_DBSCAN,\n","    'LOF': metrics_Local_Outlier_Factor\n","}\n","\n","# Define metrics names and positions\n","metrics_names = ['True Anomaly Rate', 'True Normal Rate', 'False Anolay Rate', 'False Normal Rate']\n","index = np.arange(len(metrics_names))\n","bar_width = 0.2\n","\n","# Create the bar plots\n","plt.figure(figsize=(14, 8))\n","\n","for i, model in enumerate(model_labels):\n","    model_metrics = [metrics_dict[model][j] for j in range(len(metrics_names))]\n","    plt.bar(index + i * bar_width - (bar_width * (len(model_labels) - 1)) / 2,\n","            model_metrics,\n","            bar_width,\n","            label=model)\n","\n","# Function to add labels on top of each bar\n","def add_labels(index, metrics_names, metrics_dict, model_labels):\n","    for i, model in enumerate(model_labels):\n","        for j, metric_name in enumerate(metrics_names):\n","            plt.text(index[j] + i * bar_width - (bar_width * (len(model_labels) - 1)) / 2,\n","                     metrics_dict[model][j] + 1,\n","                     f'{metrics_dict[model][j]:.1f}%',\n","                     ha='center', va='bottom')\n","\n","# Adding labels to each bar\n","add_labels(index, metrics_names, metrics_dict, model_labels)\n","\n","# Customize the plot\n","plt.xlabel('Metrics')\n","plt.ylabel('Percentage')\n","plt.title('Comparison of Confusion Matrix Metrics Across Different Models')\n","plt.xticks(index, metrics_names)\n","plt.ylim(0, 120)\n","plt.legend(loc='upper right')\n","plt.tight_layout()\n","\n","# Show the plot\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"R_DlM7mzS82e"},"outputs":[],"source":["conf_matrix_NN_AE = confusion_matrix(y_true, y_pred)\n","conf_matrix_isolation_Forest = confusion_matrix(y_true_model_IF_original, y_pred_model_IF_original)\n","conf_matrix_DBSCAN = confusion_matrix(y_true_DBSCAN_Original, y_pred_DBSCAN_Original)\n","conf_matrix_Local_Outlier_Factor = confusion_matrix(y_true_LOF_original, y_pred_LOF_original)\n","# Extracting values from the confusion matrix\n","TNs, FPs, FNs, TPs = [], [], [], []\n","for conf_matrix in [conf_matrix_isolation_Forest,conf_matrix_DBSCAN ,conf_matrix_Local_Outlier_Factor ,conf_matrix_NN_AE]:\n","    TN, FP, FN, TP = conf_matrix.ravel()\n","    TNs.append(TN)\n","    FPs.append(FP)\n","    FNs.append(FN)\n","    TPs.append(TP)\n","\n","# Define model names\n","model_names = ['IF', 'DBSCAN','LOF','NN-AE']\n","\n","# Calculate the percentages for each model\n","true_negative_rates = [(TN / (TN + FP)) * 100 for TN, FP in zip(TNs, FPs)]\n","false_positive_rates = [(FP / (TN + FP)) * 100 for TN, FP in zip(TNs, FPs)]\n","true_positive_rates = [(TP / (TP + FN)) * 100 for TP, FN in zip(TPs, FNs)]\n","false_negative_rates = [(FN / (TP + FN)) * 100 for TP, FN in zip(TPs, FNs)]\n","\n","# Plotting\n","plt.figure(figsize=(15, 8))\n","\n","# Number of models\n","num_models = len(true_negative_rates)\n","\n","# Plot bars for each rate\n","bar_width = 0.2\n","index = np.arange(num_models)\n","\n","# Function to add labels on top of each bar\n","def add_labels(bars):\n","    for bar in bars:\n","        height = bar.get_height()\n","        plt.annotate(f'{height:.0f}%',\n","                     xy=(bar.get_x() + bar.get_width() / 2, height),\n","                     xytext=(0, 3),  # 3 points vertical offset\n","                     textcoords=\"offset points\",\n","                     ha='center', va='bottom')\n","\n","tn_bars = plt.bar(index, true_negative_rates, bar_width, label='TN rate', color='blue', alpha=0.7)\n","fp_bars = plt.bar(index + bar_width, false_positive_rates, bar_width, label='FA rate', color='green', alpha=0.7)\n","tp_bars = plt.bar(index + 2 * bar_width, true_positive_rates, bar_width, label='TA rate', color='red', alpha=0.7)\n","fn_bars = plt.bar(index + 3 * bar_width, false_negative_rates, bar_width, label='FN Rate', color='purple', alpha=0.7)\n","\n","# Adding labels to each bar\n","add_labels(tn_bars)\n","add_labels(fp_bars)\n","add_labels(tp_bars)\n","add_labels(fn_bars)\n","\n","plt.xlabel('Models')\n","plt.ylabel('Percentage')\n","plt.title('Rates by Model')\n","plt.xticks(index + 1.5 * bar_width, model_names)\n","plt.legend(loc='upper right')\n","plt.tight_layout()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nvrquTWyS82f"},"outputs":[],"source":["# Plot ROC curve for each model\n","plt.figure(figsize=(8, 6))\n","\n","fpr_NN_AE, tpr_NN_AE, _ = roc_curve(y_true, y_pred)\n","auc_NN_AE = auc(fpr_NN_AE, tpr_NN_AE)\n","plt.plot(fpr_NN_AE, tpr_NN_AE, label=f'NN-AE (AUC = {auc_NN_AE:.2f})')\n","\n","fpr_IF, tpr_IF, _ = roc_curve(y_true_model_IF_original, y_pred_model_IF_original)\n","auc_IF = auc(fpr_IF, tpr_IF)\n","plt.plot(fpr_IF, tpr_IF, label=f'IF (AUC = {auc_IF:.2f})')\n","\n","fpr_DBSCAN, tpr_DBSCAN, _ = roc_curve(y_true_DBSCAN_Original, y_pred_DBSCAN_Original)\n","auc_DBSCAN = auc(fpr_DBSCAN, tpr_DBSCAN)\n","plt.plot(fpr_DBSCAN, tpr_DBSCAN, label=f'DBSCAN (AUC = {auc_DBSCAN:.2f})')\n","\n","fpr_LOF, tpr_LOF, _ = roc_curve(y_true_LOF_original, y_pred_LOF_original)\n","auc_LOF = auc(fpr_LOF, tpr_LOF)\n","plt.plot(fpr_LOF, tpr_LOF, label=f'LOF (AUC = {auc_LOF:.2f})')\n","\n","plt.plot([0, 1], [0, 1], 'k--', label='Random Guessing')\n","plt.xlabel('False Positive Rate')\n","plt.ylabel('True Positive Rate')\n","plt.title('ROC Curve Comparison')\n","plt.legend(loc='lower right')\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YW0r1w2MS82f"},"outputs":[],"source":["# Calculate accuracy, precision, recall, and F1-score for each model\n","accuracy_NN_AE = accuracy_score(y_true, y_pred)\n","precision_NN_AE = precision_score(y_true, y_pred)\n","recall_NN_AE = recall_score(y_true, y_pred)\n","f1_NN_AE = f1_score(y_true, y_pred)\n","\n","accuracy_IF = accuracy_score(y_true_model_IF_original, y_pred_model_IF_original)\n","precision_IF = precision_score(y_true_model_IF_original, y_pred_model_IF_original)\n","recall_IF = recall_score(y_true_model_IF_original, y_pred_model_IF_original)\n","f1_IF = f1_score(y_true_model_IF_original, y_pred_model_IF_original)\n","\n","accuracy_DBSCAN = accuracy_score(y_true_DBSCAN_Original, y_pred_DBSCAN_Original)\n","precision_DBSCAN = precision_score(y_true_DBSCAN_Original, y_pred_DBSCAN_Original)\n","recall_DBSCAN = recall_score(y_true_DBSCAN_Original, y_pred_DBSCAN_Original)\n","f1_DBSCAN = f1_score(y_true_DBSCAN_Original, y_pred_DBSCAN_Original)\n","\n","accuracy_LOF = accuracy_score(y_true_LOF_original, y_pred_LOF_original)\n","precision_LOF = precision_score(y_true_LOF_original, y_pred_LOF_original)\n","recall_LOF = recall_score(y_true_LOF_original, y_pred_LOF_original)\n","f1_LOF = f1_score(y_true_LOF_original, y_pred_LOF_original)\n","\n","# Collect all metrics in the specified model order\n","model_labels = ['NN-AE', 'IF', 'DBSCAN', 'LOF']\n","metrics_dict = {\n","    'NN-AE': [accuracy_NN_AE, precision_NN_AE, recall_NN_AE, f1_NN_AE],\n","    'IF': [accuracy_IF, precision_IF, recall_IF, f1_IF],\n","    'DBSCAN': [accuracy_DBSCAN, precision_DBSCAN, recall_DBSCAN, f1_DBSCAN],\n","    'LOF': [accuracy_LOF, precision_LOF, recall_LOF, f1_LOF]\n","}\n","\n","# Define metrics names and positions\n","metrics_names = ['Accuracy', 'Precision', 'Recall', 'F1-score']\n","index = np.arange(len(metrics_names))\n","bar_width = 0.2\n","\n","# Create the bar plots\n","plt.figure(figsize=(14, 8))\n","for i, model in enumerate(model_labels):\n","    model_metrics = [metrics_dict[model][j] for j in range(len(metrics_names))]\n","    plt.bar(index + i * bar_width - (bar_width * (len(model_labels) - 1)) / 2, model_metrics, bar_width, label=model)\n","\n","# Function to add labels on top of each bar\n","def add_labels(index, metrics_names, metrics_dict, model_labels):\n","    for i, model in enumerate(model_labels):\n","        for j, metric_name in enumerate(metrics_names):\n","            plt.text(index[j] + i * bar_width - (bar_width * (len(model_labels) - 1)) / 2, metrics_dict[model][j] + 0.01, f'{metrics_dict[model][j]:.2f}', ha='center', va='bottom')\n","\n","# Adding labels to each bar\n","add_labels(index, metrics_names, metrics_dict, model_labels)\n","\n","# Customize the plot\n","plt.xlabel('Metrics')\n","plt.ylabel('Percentage')\n","plt.title('Comparison of Model Performance Metrics')\n","plt.xticks(index, metrics_names)\n","plt.ylim(0, 1.1)\n","plt.legend(loc='upper right')\n","plt.tight_layout()\n","\n","# Show the plot\n","plt.show()"]},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# Define confusion matrices\n","conf_matrix_isolation_Forest = np.array([[274996, 0], [131843, 142]])\n","conf_matrix_DBSCAN = np.array([[268314, 6682], [131656, 329]])\n","conf_matrix_Local_Outlier_Factor = np.array([[271462, 3534], [131449, 536]])\n","conf_matrix_NN_AE = np.array([[274031, 965], [0, 131985]])\n","\n","# Define additional confusion matrices with _90 and _65\n","conf_matrix_isolation_Forest_90 = np.array([[274996, 0], [131784, 201]])\n","conf_matrix_DBSCAN_90 = np.array([[268314, 6682], [131656, 329]])\n","conf_matrix_Local_Outlier_Factor_90 = np.array([[271462, 3534], [131449, 536]])\n","conf_matrix_NN_AE_90 = np.array([[274077, 919], [0, 131985]])\n","\n","conf_matrix_isolation_Forest_65 = np.array([[274996, 0], [131764, 221]])\n","conf_matrix_DBSCAN_65 = np.array([[268314, 6682], [131656, 329]])\n","conf_matrix_Local_Outlier_Factor_65 = np.array([[271462, 3534], [131449, 536]])\n","conf_matrix_NN_AE_65 = np.array([[274394, 602], [0, 131985]])\n","\n","# Function to calculate metrics from confusion matrix\n","def calculate_metrics(conf_matrix):\n","    TN, FP, FN, TP = conf_matrix.ravel()\n","    accuracy = (TP + TN) / (TP + TN + FP + FN) * 100 if (TP + TN + FP + FN) > 0 else 0\n","    precision = TP / (TP + FP) * 100 if (TP + FP) > 0 else 0\n","    recall = TP / (TP + FN) * 100 if (TP + FN) > 0 else 0\n","    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n","    return [accuracy, precision, recall, f1_score]\n","\n","# Calculate metrics for each model and for the new confusion matrices\n","metrics_NN_AE = calculate_metrics(conf_matrix_NN_AE)\n","metrics_isolation_Forest = calculate_metrics(conf_matrix_isolation_Forest)\n","metrics_DBSCAN = calculate_metrics(conf_matrix_DBSCAN)\n","metrics_Local_Outlier_Factor = calculate_metrics(conf_matrix_Local_Outlier_Factor)\n","\n","metrics_NN_AE_90 = calculate_metrics(conf_matrix_NN_AE_90)\n","metrics_isolation_Forest_90 = calculate_metrics(conf_matrix_isolation_Forest_90)\n","metrics_DBSCAN_90 = calculate_metrics(conf_matrix_DBSCAN_90)\n","metrics_Local_Outlier_Factor_90 = calculate_metrics(conf_matrix_Local_Outlier_Factor_90)\n","\n","metrics_NN_AE_65 = calculate_metrics(conf_matrix_NN_AE_65)\n","metrics_isolation_Forest_65 = calculate_metrics(conf_matrix_isolation_Forest_65)\n","metrics_DBSCAN_65 = calculate_metrics(conf_matrix_DBSCAN_65)\n","metrics_Local_Outlier_Factor_65 = calculate_metrics(conf_matrix_Local_Outlier_Factor_65)\n","\n","# Collect metrics in a dictionary\n","model_labels = ['NN-AE', 'IF', 'DBSCAN', 'LOF']\n","metrics_dict = {\n","    'NN-AE': [metrics_NN_AE, metrics_NN_AE_90, metrics_NN_AE_65],\n","    'IF': [metrics_isolation_Forest, metrics_isolation_Forest_90, metrics_isolation_Forest_65],\n","    'DBSCAN': [metrics_DBSCAN, metrics_DBSCAN_90, metrics_DBSCAN_65],\n","    'LOF': [metrics_Local_Outlier_Factor, metrics_Local_Outlier_Factor_90, metrics_Local_Outlier_Factor_65]\n","}\n","\n","# Define metric names and bar plot settings\n","metrics_names = ['Accuracy', 'Precision', 'Recall', 'F1-score']\n","index = np.arange(len(metrics_names))\n","bar_width = 0.2\n","\n","# Create a 3x1 grid of subplots\n","fig, axes = plt.subplots(3, 1, figsize=(18, 10))\n","\n","# Subplots: Bar plots for each subplot\n","for i, model in enumerate(model_labels):\n","    for j in range(2):  # Iterate over the first two confusion matrices (original, 90)\n","        metrics = metrics_dict[model][j]\n","        if j == 0:\n","            bars = axes[0].bar(index + i * bar_width - (bar_width * (len(model_labels) - 1)) / 2, metrics, bar_width, label=model)\n","        else:\n","            bars = axes[1].bar(index + i * bar_width - (bar_width * (len(model_labels) - 1)) / 2, metrics, bar_width, label=model)\n","\n","        # Add percentage labels on top of the bars\n","        for bar in bars:\n","            height = bar.get_height()\n","            if j == 0:\n","                axes[0].text(bar.get_x() + bar.get_width() / 2, height + 1, f'{height:.1f}', ha='center', va='bottom', fontsize=15)\n","            else:\n","                axes[1].text(bar.get_x() + bar.get_width() / 2, height + 1, f'{height:.1f}', ha='center', va='bottom', fontsize=15)\n","\n","# For the third subplot (bottom one), use the 65% confusion matrices\n","for i, model in enumerate(model_labels):\n","    metrics = metrics_dict[model][2]\n","    bars = axes[2].bar(index + i * bar_width - (bar_width * (len(model_labels) - 1)) / 2, metrics, bar_width, label=model)\n","\n","    # Add percentage labels on top of the bars\n","    for bar in bars:\n","        height = bar.get_height()\n","        axes[2].text(bar.get_x() + bar.get_width() / 2, height + 1, f'{height:.1f}', ha='center', va='bottom', fontsize=15)\n","\n","# Set common settings for all subplots\n","ii = 0\n","for ax in axes.flat:\n","    if ii == 0:\n","        ax.legend(loc='best', fontsize=20, bbox_to_anchor=(1.00, 0.5))\n","        ii = ii + 1\n","    ax.set_xticks(index)\n","    ax.set_xticklabels(metrics_names, fontsize=20)\n","    ax.set_ylabel('Percentage', fontsize=20)\n","    ax.set_ylim(0, 130)  # Set y-axis limit from 0 to 130\n","    ax.yaxis.set_tick_params(labelsize=15)\n","\n","# Set titles for each subplot\n","axes[0].set_title('Without resampling', fontsize=20)\n","axes[1].set_title('Resampling 90s', fontsize=20)\n","axes[2].set_title('Resampling 65s', fontsize=20)\n","\n","# Adjust layout\n","plt.tight_layout()\n","plt.show()\n"],"metadata":{"id":"HodAbM2pwRy9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# Define confusion matrices\n","conf_matrix_isolation_Forest = np.array([[274996, 0], [131843, 142]])\n","conf_matrix_DBSCAN = np.array([[268314, 6682], [131656, 329]])\n","conf_matrix_Local_Outlier_Factor = np.array([[271462, 3534], [131449, 536]])\n","conf_matrix_NN_AE = np.array([[274031, 965], [0, 131985]])\n","\n","# Define additional confusion matrices with _90 and _65\n","conf_matrix_isolation_Forest_90 = np.array([[274996, 0], [131784, 201]])\n","conf_matrix_DBSCAN_90 = np.array([[268314, 6682], [131656, 329]])\n","conf_matrix_Local_Outlier_Factor_90 = np.array([[271462, 3534], [131449, 536]])\n","conf_matrix_NN_AE_90 = np.array([[274077, 919], [0, 131985]])\n","\n","conf_matrix_isolation_Forest_65 = np.array([[274996, 0], [131764, 221]])\n","conf_matrix_DBSCAN_65 = np.array([[268314, 6682], [131656, 329]])\n","conf_matrix_Local_Outlier_Factor_65 = np.array([[271462, 3534], [131449, 536]])\n","conf_matrix_NN_AE_65 = np.array([[274394, 602], [0, 131985]])\n","\n","# Function to calculate metrics from confusion matrix\n","def calculate_metrics(conf_matrix, auc=0):\n","    TN, FP, FN, TP = conf_matrix.ravel()\n","    accuracy = (TP + TN) / (TP + TN + FP + FN) * 100 if (TP + TN + FP + FN) > 0 else 0\n","    precision = TP / (TP + FP) * 100 if (TP + FP) > 0 else 0\n","    recall = TP / (TP + FN) * 100 if (TP + FN) > 0 else 0\n","    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n","    return [accuracy, precision, recall, f1_score, auc]\n","\n","# Simulate AUC values for demonstration purposes\n","simulated_aucs = {\n","    'NN-AE': [99.82, 99.83, 99.89],\n","    'IF': [50.05, 50.07, 50.08],\n","    'DBSCAN': [48.90, 48.90, 48.90],\n","    'LOF': [49.56, 49.56, 49.56]\n","}\n","\n","# Calculate metrics for each model and for the new confusion matrices\n","metrics_NN_AE = calculate_metrics(conf_matrix_NN_AE, simulated_aucs['NN-AE'][0])\n","metrics_isolation_Forest = calculate_metrics(conf_matrix_isolation_Forest, simulated_aucs['IF'][0])\n","metrics_DBSCAN = calculate_metrics(conf_matrix_DBSCAN, simulated_aucs['DBSCAN'][0])\n","metrics_Local_Outlier_Factor = calculate_metrics(conf_matrix_Local_Outlier_Factor, simulated_aucs['LOF'][0])\n","\n","metrics_NN_AE_90 = calculate_metrics(conf_matrix_NN_AE_90, simulated_aucs['NN-AE'][1])\n","metrics_isolation_Forest_90 = calculate_metrics(conf_matrix_isolation_Forest_90, simulated_aucs['IF'][1])\n","metrics_DBSCAN_90 = calculate_metrics(conf_matrix_DBSCAN_90, simulated_aucs['DBSCAN'][1])\n","metrics_Local_Outlier_Factor_90 = calculate_metrics(conf_matrix_Local_Outlier_Factor_90, simulated_aucs['LOF'][1])\n","\n","metrics_NN_AE_65 = calculate_metrics(conf_matrix_NN_AE_65, simulated_aucs['NN-AE'][2])\n","metrics_isolation_Forest_65 = calculate_metrics(conf_matrix_isolation_Forest_65, simulated_aucs['IF'][2])\n","metrics_DBSCAN_65 = calculate_metrics(conf_matrix_DBSCAN_65, simulated_aucs['DBSCAN'][2])\n","metrics_Local_Outlier_Factor_65 = calculate_metrics(conf_matrix_Local_Outlier_Factor_65, simulated_aucs['LOF'][2])\n","\n","# Collect metrics in a dictionary\n","model_labels = ['NN-AE', 'IF', 'DBSCAN', 'LOF']\n","metrics_dict = {\n","    'NN-AE': [metrics_NN_AE, metrics_NN_AE_90, metrics_NN_AE_65],\n","    'IF': [metrics_isolation_Forest, metrics_isolation_Forest_90, metrics_isolation_Forest_65],\n","    'DBSCAN': [metrics_DBSCAN, metrics_DBSCAN_90, metrics_DBSCAN_65],\n","    'LOF': [metrics_Local_Outlier_Factor, metrics_Local_Outlier_Factor_90, metrics_Local_Outlier_Factor_65]\n","}\n","\n","# Define metric names and bar plot settings\n","metrics_names = ['Accuracy', 'Precision', 'Recall', 'F1-score', 'AUC']\n","index = np.arange(len(metrics_names))\n","bar_width = 0.2\n","\n","# Create a 3x1 grid of subplots\n","fig, axes = plt.subplots(3, 1, figsize=(18, 10))\n","\n","# Subplots: Bar plots for each subplot\n","for i, model in enumerate(model_labels):\n","    for j in range(2):  # Iterate over the first two confusion matrices (original, 90)\n","        metrics = metrics_dict[model][j]\n","        if j == 0:\n","            bars = axes[0].bar(index + i * bar_width - (bar_width * (len(model_labels) - 1)) / 2, metrics, bar_width, label=model)\n","        else:\n","            bars = axes[1].bar(index + i * bar_width - (bar_width * (len(model_labels) - 1)) / 2, metrics, bar_width, label=model)\n","\n","        # Add percentage labels on top of the bars\n","        for bar in bars:\n","            height = bar.get_height()\n","            if j == 0:\n","                axes[0].text(bar.get_x() + bar.get_width() / 2, height + 1, f'{height:.1f}', ha='center', va='bottom', fontsize=15)\n","            else:\n","                axes[1].text(bar.get_x() + bar.get_width() / 2, height + 1, f'{height:.1f}', ha='center', va='bottom', fontsize=15)\n","\n","# For the third subplot (bottom one), use the 65% confusion matrices\n","for i, model in enumerate(model_labels):\n","    metrics = metrics_dict[model][2]\n","    bars = axes[2].bar(index + i * bar_width - (bar_width * (len(model_labels) - 1)) / 2, metrics, bar_width, label=model)\n","\n","    # Add percentage labels on top of the bars\n","    for bar in bars:\n","        height = bar.get_height()\n","        axes[2].text(bar.get_x() + bar.get_width() / 2, height + 1, f'{height:.1f}', ha='center', va='bottom', fontsize=15)\n","\n","# Set common settings for all subplots\n","ii = 0\n","for ax in axes.flat:\n","    if ii == 0:\n","        ax.legend(loc='best', fontsize=20, bbox_to_anchor=(1.00, 0.5))\n","        ii = ii + 1\n","    ax.set_xticks(index)\n","    ax.set_xticklabels(metrics_names, fontsize=20)\n","    ax.set_ylabel('Percentage', fontsize=20)\n","    ax.set_ylim(0, 130)  # Set y-axis limit from 0 to 130\n","    ax.yaxis.set_tick_params(labelsize=15)\n","\n","# Set titles for each subplot\n","axes[0].set_title('Without resampling', fontsize=20)\n","axes[1].set_title('Resampling 90s', fontsize=20)\n","axes[2].set_title('Resampling 65s', fontsize=20)\n","\n","# Adjust layout\n","plt.tight_layout()\n","plt.show()\n"],"metadata":{"id":"c6Nd9y3tXmho"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b9xn8zlXS82g"},"outputs":[],"source":["# Sample data\n","models = ['IF: without resampling ', 'IF: resampling 90s', 'IF: resampling 65s', 'DBSCAN: without resampling', 'DBSCAN: resampling 90s', 'DBSCAN: resampling 65s','LOF: without resampling', 'LOF: resampling 90s', 'LOF: resampling 65s', 'NN-AE without resampling', 'NN-AE: resampling 90s', 'NN-AE: resampling 65s']\n","accuracies = [0.6760,0.6762,0.6761, 0.6600, 0.6600, 0.6600, 0.6683, 0.6683, 0.6683, 0.9976, 0.9977,0.9985]\n","f1_scores = [0.0021, 0.0033, 0.0030, 0.0047, 0.0047,0.0047, 0.0078, 0.0078,  0.0078, 0.9963, 0.9980,0.9977]\n","recalls = [0.0010, 0.0016, 0.0015, 0.0024, 0.0024, 0.0024, 0.0040, 0.0040,  0.0040, 1.0, 1.0, 1.0]\n","precisions = [1.0, 1.0, 1.0, 0.0469, 0.0469, 0.0469, 0.1316, 0.1316, 0.1316, 0.9927, 0.9861,0.9854]\n","specificities = [1.0, 1.0, 1.0, 0.9757,0.9757, 0.9757, 0.9871, 0.9871, 0.9871, 0.9965, 0.9981,0.9978]\n","auc_scores = [0.5005, 0.5008,  0.5007, 0.4890, 0.4890, 0.4890, 0.4956, 0.4956, 0.4956, 0.9983, 0.9990,0.9989]\n","\n","# Confidence intervals for each metric\n","ci_acc = [0.0011, 0.0012, 0.0012, 0.0011, 0.0012, 0.0012, 0.0013, 0.0012, 0.0013, 0.0013, 0.0002, 0.0002]\n","ci_f1 = [0.0003, 0.0004, 0.0003, 0.0004, 0.0004, 0.0005, 0.0006, 0.0005, 0.0006, 0.0006, 0.0003, 0.0002]\n","ci_recall = [0.0001, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0003, 0.0003, 0.0003, 0.0003, 0, 0]\n","ci_precision = [0, 0, 0,0.0036, 0.0040, 0.0040, 0.0092, 0.0091, 0.0084, 0.0092, 0.0006, 0.0005]\n","ci_specificity = [0, 0, 0, 0.0004, 0.0005, 0.0004, 0.0004, 0.0003, 0.0003, 0.0002, 0.0003, 0.0003]\n","ci_auc = [0.0001, 0.0001, 0.0001, 0.0003, 0.0003, 0.0002, 0.0003, 0.0002, 0.0002, 0.0001, 0.0001, 0.0001]\n","\n","# Colors for different metrics\n","colors = {\n","    'Accuracy': 'red',\n","    'F1-Score': 'blue',\n","    'Recall': 'green',\n","    'Precision': 'purple',\n","    'Specificity': 'orange',\n","    'AUC': 'brown'\n","}\n","\n","# Create plot\n","fig, ax = plt.subplots(figsize=(14, 14))\n","\n","# Plot each model with its metrics and confidence intervals\n","for i in range(len(models)):\n","    base_pos = i * 7\n","    ax.errorbar(accuracies[i], base_pos + 5, xerr=ci_acc[i], fmt='o', color=colors['Accuracy'], capsize=2, capthick=1, markersize=4)\n","    ax.errorbar(f1_scores[i], base_pos + 4, xerr=ci_f1[i], fmt='o', color=colors['F1-Score'], capsize=2, capthick=1, markersize=4)\n","    ax.errorbar(recalls[i], base_pos + 3, xerr=ci_recall[i], fmt='o', color=colors['Recall'], capsize=2, capthick=1, markersize=4)\n","    ax.errorbar(precisions[i], base_pos + 2, xerr=ci_precision[i], fmt='o', color=colors['Precision'], capsize=2, capthick=1, markersize=4)\n","    ax.errorbar(specificities[i], base_pos + 1, xerr=ci_specificity[i], fmt='o', color=colors['Specificity'], capsize=2, capthick=1, markersize=4)\n","    ax.errorbar(auc_scores[i], base_pos, xerr=ci_auc[i], fmt='o', color=colors['AUC'], capsize=2, capthick=1, markersize=4)\n","\n","# Customizing the plot\n","ax.set_yticks([i * 7 + 2.5 for i in range(len(models))])\n","ax.set_yticklabels(models, fontsize=20)\n","ax.set_xticks(np.arange(0, 1.1, 0.1))\n","ax.set_xlabel('Percentage [x100%]', fontsize=20)\n","ax.set_ylabel('', fontsize=20)\n","ax.grid(True, linestyle='--', alpha=0.7, axis='x')\n","ax.xaxis.set_tick_params(labelsize=15)\n","\n","# Adding horizontal lines to separate models\n","for i in range(1, len(models)):\n","    ax.axhline(y=i * 7 - 0.5, color='black', linestyle='--', linewidth=1)\n","\n","# Add a legend outside the plot\n","legend_handles = [\n","    plt.Line2D([0], [0], color=colors['Accuracy'], lw=2, label='Accuracy'),\n","    plt.Line2D([0], [0], color=colors['F1-Score'], lw=2, label='F1-Score'),\n","    plt.Line2D([0], [0], color=colors['Recall'], lw=2, label='Recall'),\n","    plt.Line2D([0], [0], color=colors['Precision'], lw=2, label='Precision'),\n","    plt.Line2D([0], [0], color=colors['Specificity'], lw=2, label='Specificity'),\n","    plt.Line2D([0], [0], color=colors['AUC'], lw=2, label='AUC')\n","]\n","ax.legend(handles=legend_handles, loc='best', bbox_to_anchor=(1, 0.5), fontsize=20, frameon=False)\n","\n","# plot\n","ax.spines['top'].set_visible(False)\n","ax.spines['right'].set_visible(False)\n","ax.spines['left'].set_color('black')\n","ax.spines['bottom'].set_color('black')\n","ax.xaxis.label.set_color('black')\n","ax.yaxis.label.set_color('black')\n","ax.tick_params(axis='x', colors='black')\n","ax.tick_params(axis='y', colors='black')\n","\n","plt.show()"]},{"cell_type":"code","source":["# Updated order for models\n","models = [\n","    'DBSCAN: resampling 65s', 'LOF: resampling 65s', 'IF: resampling 65s', 'NN-AE: resampling 65s',\n","    'DBSCAN: resampling 90s', 'LOF: resampling 90s', 'IF: resampling 90s', 'NN-AE: resampling 90s',\n","    'DBSCAN: without resampling', 'LOF: without resampling', 'IF: without resampling', 'NN-AE: without resampling'\n","]\n","\n","# Metrics updated in the specified order\n","accuracies = [0.6600, 0.6683, 0.6761, 0.9985, 0.6600, 0.6683, 0.6762, 0.9977, 0.6600, 0.6683, 0.6760, 0.9976]\n","f1_scores = [0.0047, 0.0078, 0.0030, 0.9977, 0.0047, 0.0078, 0.0033, 0.9980, 0.0047, 0.0078, 0.0021, 0.9963]\n","recalls = [0.0024, 0.0040, 0.0015, 1.0, 0.0024, 0.0040, 0.0016, 1.0, 0.0024, 0.0040, 0.0010, 1.0]\n","precisions = [0.0469, 0.1316, 1.0, 0.9854, 0.0469, 0.1316, 1.0, 0.9861, 0.0469, 0.1316, 1.0, 0.9927]\n","specificities = [0.9757, 0.9871, 1.0, 0.9978, 0.9757, 0.9871, 1.0, 0.9981, 0.9757, 0.9871, 1.0, 0.9965]\n","auc_scores = [0.4890, 0.4956, 0.5007, 0.9989, 0.4890, 0.4956, 0.5008, 0.9990, 0.4890, 0.4956, 0.5005, 0.9983]\n","\n","# Confidence intervals for each metric (matching the new order)\n","ci_acc = [0.0012, 0.0013, 0.0012, 0.0002, 0.0012, 0.0012, 0.0012, 0.0002, 0.0011, 0.0013, 0.0011, 0.0013]\n","ci_f1 = [0.0004, 0.0006, 0.0003, 0.0002, 0.0004, 0.0005, 0.0004, 0.0003, 0.0004, 0.0006, 0.0003, 0.0006]\n","ci_recall = [0.0002, 0.0003, 0.0002, 0, 0.0002, 0.0003, 0.0002, 0, 0.0002, 0.0003, 0.0001, 0.0003]\n","ci_precision = [0.0040, 0.0084, 0, 0.0005, 0.0040, 0.0091, 0, 0.0006, 0.0036, 0.0092, 0, 0.0092]\n","ci_specificity = [0.0004, 0.0003, 0, 0.0003, 0.0005, 0.0003, 0, 0.0003, 0.0004, 0.0003, 0, 0.0002]\n","ci_auc = [0.0003, 0.0002, 0.0001, 0.0001, 0.0003, 0.0002, 0.0001, 0.0001, 0.0003, 0.0002, 0.0001, 0.0001]\n","\n","# Colors for different metrics\n","colors = {\n","    'Accuracy': 'red',\n","    'F1-Score': 'blue',\n","    'Recall': 'green',\n","    'Precision': 'purple',\n","    'Specificity': 'orange',\n","    'AUC': 'brown'\n","}\n","\n","# Create plot\n","fig, ax = plt.subplots(figsize=(14, 14))\n","\n","# Plot each model with its metrics and confidence intervals\n","for i in range(len(models)):\n","    base_pos = i * 7\n","    ax.errorbar(accuracies[i], base_pos + 5, xerr=ci_acc[i], fmt='o', color=colors['Accuracy'], capsize=2, capthick=1, markersize=4)\n","    ax.errorbar(f1_scores[i], base_pos + 4, xerr=ci_f1[i], fmt='o', color=colors['F1-Score'], capsize=2, capthick=1, markersize=4)\n","    ax.errorbar(recalls[i], base_pos + 3, xerr=ci_recall[i], fmt='o', color=colors['Recall'], capsize=2, capthick=1, markersize=4)\n","    ax.errorbar(precisions[i], base_pos + 2, xerr=ci_precision[i], fmt='o', color=colors['Precision'], capsize=2, capthick=1, markersize=4)\n","    ax.errorbar(specificities[i], base_pos + 1, xerr=ci_specificity[i], fmt='o', color=colors['Specificity'], capsize=2, capthick=1, markersize=4)\n","    ax.errorbar(auc_scores[i], base_pos, xerr=ci_auc[i], fmt='o', color=colors['AUC'], capsize=2, capthick=1, markersize=4)\n","\n","# Customizing the plot\n","ax.set_yticks([i * 7 + 2.5 for i in range(len(models))])\n","ax.set_yticklabels(models, fontsize=20)\n","ax.set_xticks(np.arange(0, 1.1, 0.1))\n","ax.set_xlabel('Percentage [x100%]', fontsize=20)\n","ax.set_ylabel('', fontsize=20)\n","ax.grid(True, linestyle='--', alpha=0.7, axis='x')\n","ax.xaxis.set_tick_params(labelsize=15)\n","\n","# Adding horizontal lines to separate models\n","# Adding horizontal lines to separate models\n","for i in range(1, len(models)):\n","    if i == 4 or i == 8:\n","        ax.axhline(y=i * 7 - 0.5, color='black', linestyle='-', linewidth=2)  # Bold line\n","    else:\n","        ax.axhline(y=i * 7 - 0.5, color='black', linestyle='--', linewidth=1)\n","\n","# Add a legend outside the plot\n","legend_handles = [\n","    plt.Line2D([0], [0], color=colors['Accuracy'], lw=2, label='Accuracy'),\n","    plt.Line2D([0], [0], color=colors['F1-Score'], lw=2, label='F1-Score'),\n","    plt.Line2D([0], [0], color=colors['Recall'], lw=2, label='Recall'),\n","    plt.Line2D([0], [0], color=colors['Precision'], lw=2, label='Precision'),\n","    plt.Line2D([0], [0], color=colors['Specificity'], lw=2, label='Specificity'),\n","    plt.Line2D([0], [0], color=colors['AUC'], lw=2, label='AUC')\n","]\n","ax.legend(handles=legend_handles, loc='best', bbox_to_anchor=(1, 0.5), fontsize=20, frameon=False)\n","\n","# Plot customizations\n","ax.spines['top'].set_visible(False)\n","ax.spines['right'].set_visible(False)\n","ax.spines['left'].set_color('black')\n","ax.spines['bottom'].set_color('black')\n","ax.xaxis.label.set_color('black')\n","ax.yaxis.label.set_color('black')\n","ax.tick_params(axis='x', colors='black')\n","ax.tick_params(axis='y', colors='black')\n","\n","plt.show()"],"metadata":{"id":"6n1TjFTzbrgT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Updated order for models\n","models = [\n","    'NN-AE: resampling 65s', 'LOF: resampling 65s', 'DBSCAN: resampling 65s', 'IF: resampling 65s',\n","    'NN-AE: resampling 90s', 'LOF: resampling 90s', 'DBSCAN: resampling 90s', 'IF: resampling 90s',\n","    'NN-AE: without resampling', 'LOF: without resampling', 'DBSCAN: without resampling', 'IF: without resampling'\n","]\n","\n","# Metrics updated in the specified order\n","accuracies = [0.9985, 0.6683, 0.6600, 0.6761, 0.9977, 0.6683, 0.6600, 0.6762, 0.9976, 0.6683, 0.6600, 0.6760]\n","f1_scores = [0.9977, 0.0078, 0.0047, 0.0030, 0.9980, 0.0078, 0.0047, 0.0033, 0.9963, 0.0078, 0.0047, 0.0021]\n","recalls = [1.0, 0.0040, 0.0024, 0.0015, 1.0, 0.0040, 0.0024, 0.0016, 1.0, 0.0040, 0.0024, 0.0010]\n","precisions = [0.9854, 0.1316, 0.0469, 1.0, 0.9861, 0.1316, 0.0469, 1.0, 0.9927, 0.1316, 0.0469, 1.0]\n","specificities = [0.9978, 0.9871, 0.9757, 1.0, 0.9981, 0.9871, 0.9757, 1.0, 0.9965, 0.9871, 0.9757, 1.0]\n","auc_scores = [0.9989, 0.4956, 0.4890, 0.5007, 0.9990, 0.4956, 0.4890, 0.5008, 0.9983, 0.4956, 0.4890, 0.5005]\n","\n","# Confidence intervals for each metric (matching the new order)\n","ci_acc = [0.0002, 0.0013, 0.0012, 0.0012, 0.0002, 0.0012, 0.0012, 0.0012, 0.0013, 0.0013, 0.0011, 0.0011]\n","ci_f1 = [0.0002, 0.0006, 0.0004, 0.0003, 0.0003, 0.0005, 0.0004, 0.0004, 0.0006, 0.0006, 0.0004, 0.0003]\n","ci_recall = [0, 0.0003, 0.0002, 0.0002, 0, 0.0003, 0.0002, 0.0002, 0.0003, 0.0003, 0.0002, 0.0001]\n","ci_precision = [0.0005, 0.0084, 0.0040, 0, 0.0006, 0.0091, 0.0040, 0, 0.0092, 0.0092, 0.0036, 0]\n","ci_specificity = [0.0003, 0.0003, 0.0004, 0, 0.0003, 0.0003, 0.0005, 0, 0.0002, 0.0003, 0.0004, 0]\n","ci_auc = [0.0001, 0.0002, 0.0003, 0.0001, 0.0001, 0.0002, 0.0003, 0.0001, 0.0001, 0.0002, 0.0003, 0.0001]\n","\n","# Colors for different metrics\n","colors = {\n","    'Accuracy': 'red',\n","    'F1-Score': 'blue',\n","    'Recall': 'green',\n","    'Precision': 'purple',\n","    'Specificity': 'orange',\n","    'AUC': 'brown'\n","}\n","\n","# Create plot\n","fig, ax = plt.subplots(figsize=(14, 14))\n","\n","# Plot each model with its metrics and confidence intervals\n","for i in range(len(models)):\n","    base_pos = i * 7\n","    ax.errorbar(accuracies[i], base_pos + 5, xerr=ci_acc[i], fmt='o', color=colors['Accuracy'], capsize=2, capthick=1, markersize=4)\n","    ax.errorbar(f1_scores[i], base_pos + 4, xerr=ci_f1[i], fmt='o', color=colors['F1-Score'], capsize=2, capthick=1, markersize=4)\n","    ax.errorbar(recalls[i], base_pos + 3, xerr=ci_recall[i], fmt='o', color=colors['Recall'], capsize=2, capthick=1, markersize=4)\n","    ax.errorbar(precisions[i], base_pos + 2, xerr=ci_precision[i], fmt='o', color=colors['Precision'], capsize=2, capthick=1, markersize=4)\n","    ax.errorbar(specificities[i], base_pos + 1, xerr=ci_specificity[i], fmt='o', color=colors['Specificity'], capsize=2, capthick=1, markersize=4)\n","    ax.errorbar(auc_scores[i], base_pos, xerr=ci_auc[i], fmt='o', color=colors['AUC'], capsize=2, capthick=1, markersize=4)\n","\n","# Customizing the plot\n","ax.set_yticks([i * 7 + 2.5 for i in range(len(models))])\n","ax.set_yticklabels(models, fontsize=20)\n","ax.set_xticks(np.arange(0, 1.1, 0.1))\n","ax.set_xlabel('Percentage [x100%]', fontsize=20)\n","ax.set_ylabel('', fontsize=20)\n","ax.grid(True, linestyle='--', alpha=0.7, axis='x')\n","ax.xaxis.set_tick_params(labelsize=15)\n","\n","# Adding horizontal lines to separate models\n","for i in range(1, len(models)):\n","    if i == 4 or i == 8:\n","        ax.axhline(y=i * 7 - 0.5, color='black', linestyle='-', linewidth=2)  # Bold line\n","    else:\n","        ax.axhline(y=i * 7 - 0.5, color='black', linestyle='--', linewidth=1)\n","\n","# Add a legend outside the plot\n","legend_handles = [\n","    plt.Line2D([0], [0], color=colors['Accuracy'], lw=2, label='Accuracy'),\n","    plt.Line2D([0], [0], color=colors['F1-Score'], lw=2, label='F1-Score'),\n","    plt.Line2D([0], [0], color=colors['Recall'], lw=2, label='Recall'),\n","    plt.Line2D([0], [0], color=colors['Precision'], lw=2, label='Precision'),\n","    plt.Line2D([0], [0], color=colors['Specificity'], lw=2, label='Specificity'),\n","    plt.Line2D([0], [0], color=colors['AUC'], lw=2, label='AUC')\n","]\n","ax.legend(handles=legend_handles, loc='best', bbox_to_anchor=(1, 0.5), fontsize=20, frameon=False)\n","\n","# Plot customizations\n","ax.spines['top'].set_visible(False)\n","ax.spines['right'].set_visible(False)\n","ax.spines['left'].set_color('black')\n","ax.spines['bottom'].set_color('black')\n","ax.xaxis.label.set_color('black')\n","ax.yaxis.label.set_color('black')\n","ax.tick_params(axis='x', colors='black')\n","ax.tick_params(axis='y', colors='black')\n","\n","plt.show()\n"],"metadata":{"id":"cgJI1UxK8-o4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FiyrG-rRS82g"},"source":["Fish detection plots"]},{"cell_type":"code","source":["# Plots fish detections for a specific date with normal and anomaly detections.\n","def plot_fish_detections(data, date, legendx=None, xlabelx=None):\n","\n","    # Convert 'datetime' to datetime type if not already\n","    data['datetime'] = pd.to_datetime(data['datetime'])\n","\n","    # Filter data for the specific date\n","    specific_day_data = data[data['datetime'].dt.date == pd.to_datetime(date).date()]\n","\n","    # Plotting\n","    fig, ax = plt.subplots(figsize=(10, 3))\n","\n","    # Initialize legend handles\n","    normal_handle = None\n","    anomaly_handle = None\n","\n","    # Loop through each detection to plot a line and a circle\n","    for _, row in specific_day_data.iterrows():\n","        time = row['datetime']\n","        if row['Anomaly'] == 0:\n","            color = 'red'\n","            label = 'Normal' if normal_handle is None else \"_nolegend_\"\n","            normal_handle = True\n","        else:  # Anomaly detection\n","            color = 'blue'\n","            label = 'Anomaly' if anomaly_handle is None else \"_nolegend_\"\n","            anomaly_handle = True\n","\n","        # Plot a line from x-axis to the point\n","        plt.plot([time, time], [0, 1], color=color, label=label)\n","\n","        # Plot a circle on top of the line\n","        plt.scatter([time], [1], color=color, s=30)\n","\n","    # Formatting the plot\n","    ax.xaxis.set_major_formatter(DateFormatter('%H:%M'))\n","    ax.xaxis.set_tick_params(labelsize=11)\n","    plt.title(f'Fish Detections on {date}', fontsize=15)\n","    if xlabelx is not None:\n","      plt.xlabel('Time of the day', fontsize=15)\n","\n","    # Adding the label for the y-axis as 'Detections'\n","    plt.ylabel('Detections', fontsize=15)\n","\n","    # Hide y-axis tick values but keep the label\n","    ax.set_yticks([])\n","\n","    # Add a legend in the top-right corner\n","    if legendx is not None:\n","      plt.legend(loc='best', fontsize=15)\n","\n","    plt.tight_layout()\n","    plt.show()\n"],"metadata":{"id":"vumKp2qZcP22"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qOD4uYpDS82h"},"outputs":[],"source":["# Plots for fish detection\n","plot_fish_detections(data, '2017-01-15',legendx='y', xlabelx=None)\n","plot_fish_detections(data, '2016-12-22',legendx=None, xlabelx=None)\n","\n","plot_fish_detections(data, '2016-12-10',legendx=None, xlabelx='y')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YtwAJMqAS82h"},"outputs":[],"source":["# Ensure 'datetime' column is in datetime format\n","data['datetime'] = pd.to_datetime(data['datetime'])\n","\n","# Specify the date\n","specific_date_2016_12_22 = pd.to_datetime('2016-12-22').date()\n","specific_date_2017_01_15 = pd.to_datetime('2017-01-15').date()\n","specific_date_2016_12_10 = pd.to_datetime('2016-12-10').date()\n","\n","# Filter data for normal points for each day day\n","normal_data_2016_12_22 = data[\n","    (data['datetime'].dt.date == specific_date_2016_12_22) & (data['Anomaly'] == 0)\n","]\n","\n","normal_data_2017_01_15 = data[\n","    (data['datetime'].dt.date == specific_date_2017_01_15) & (data['Anomaly'] == 0)\n","]\n","\n","normal_data_2016_12_10 = data[\n","    (data['datetime'].dt.date == specific_date_2016_12_10) & (data['Anomaly'] == 0)\n","]"]},{"cell_type":"code","source":["def plot_resampled_detections(augmented_data, date, xlabelx=None):\n","\n","    # Filter data for the specific date\n","    specific_day_data = augmented_data[augmented_data['datetime'].dt.date == pd.to_datetime(date).date()]\n","\n","    # Initialize handles for the legend\n","    normal_handle = None\n","    anomaly_handle = None\n","\n","    # Plotting\n","    fig, ax = plt.subplots(figsize=(10, 3))\n","    for _, row in specific_day_data.iterrows():\n","        time = row['datetime']\n","        if row['Anomaly'] == 0:  # Normal detection\n","            color = 'red'\n","            label = 'Normal' if normal_handle is None else \"_nolegend_\"\n","            normal_handle = True\n","        else:  # Anomaly detection\n","            color = 'blue'\n","            label = 'Anomaly' if anomaly_handle is None else \"_nolegend_\"\n","            anomaly_handle = True\n","\n","        # Plot a line from x-axis to the point\n","        plt.plot([time, time], [0, 1], color=color, label=label)\n","\n","        # Plot a circle on top of the line\n","        plt.scatter([time], [1], color=color, s=30)\n","\n","    # Formatting the plot\n","    ax.xaxis.set_major_formatter(DateFormatter('%H:%M'))\n","    ax.xaxis.set_tick_params(labelsize=11)\n","    plt.title(f'Resampled Normal Fish Detections on {date}', fontsize=15)\n","    if xlabelx is not None:\n","      plt.xlabel('Time of the day', fontsize=15)\n","\n","    # Adding the label for the y-axis as 'Detections'\n","    plt.ylabel('Detections', fontsize=15)\n","\n","    # Hide y-axis tick values but keep the label\n","    ax.set_yticks([])\n","\n","    # Adding the legend at the top-right corner\n","    #plt.legend(loc='upper right')\n","\n","    plt.tight_layout()\n","    plt.show()"],"metadata":{"id":"hIxPymS8iThf"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3UE7cLmAS82i"},"outputs":[],"source":["#Resampled Normal Fish Detections on 2017-01-15\n","augmented_data_Normal_only_withNewAnomaly = augment_data_with_sampling(normal_data_2017_01_15)\n","plot_resampled_detections(augmented_data_Normal_only_withNewAnomaly, '2017-01-15', xlabelx=None)\n","\n","\n","#Resampled Normal Fish Detections on 2016-12-22\n","augmented_data_Normal_only_withNewAnomaly = augment_data_with_sampling(normal_data_2016_12_22)\n","plot_resampled_detections(augmented_data_Normal_only_withNewAnomaly, '2016-12-22', xlabelx=None)\n","\n","\n","#Resampled Normal Fish Detections on 2016-12-10\n","augmented_data_Normal_only_withNewAnomaly = augment_data_with_sampling(normal_data_2016_12_10)\n","plot_resampled_detections(augmented_data_Normal_only_withNewAnomaly, '2016-12-10', xlabelx='y')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fseSBSHZS82i"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2H88XX_7S82i"},"outputs":[],"source":["# Define the longitude and latitude arrays for stations\n","station_longitude = [20.55331, 20.60169, 20.6057, 20.64561, 20.64984, 20.68885, 20.68968, 20.71504, 20.7181, 20.75242, 20.75805, 20.79069, 20.79869, 20.807021, 20.82168, 20.83526, 20.84281]\n","station_latitude = [-34.26002, -34.35186, -34.34874, -34.35479, -34.3523, -34.35346, -34.35905, -34.36976, -34.37348, -34.39396, -34.39456, -34.40693, -34.40984, -34.406908, -34.3987, -34.39735, -34.40792]\n","station_labels = ['BT', 'B14', 'B13', 'B12', 'B11', 'B10', 'B9', 'B8', 'B7', 'B6', 'B5', 'B4', 'B3', 'BC', 'B2', 'Bd', 'B0']\n","station_colors = ['green'] * len(station_longitude)  # Initialize all stations as green\n","\n","# Define the stations to change the color\n","stations_to_change = ['BT', 'B12', 'B11', 'B10', 'B9', 'B8', 'B7', 'B6', 'B4', 'B3', 'BC', 'B2', 'Bd', 'B0']\n","\n","# Change the color of specified stations to red\n","for i, label in enumerate(station_labels):\n","    if label in stations_to_change:\n","        station_colors[i] = 'red'\n","\n","# Load the fish movement data\n","df = data\n","\n","# Filter the data for fishid \"A69-9001-23861a\"\n","fish_data = df.loc[df['fishid'] == \"A69-9001-23769\"]\n","\n","# Create a plot for the fish\n","plt.figure(figsize=(6, 5))  # Adjust the figure size as per your preference\n","plt.plot(fish_data['lon'], fish_data['lat'])\n","plt.xlabel('Longitude')\n","plt.ylabel('Latitude')\n","plt.title('Fish A69-9001-23769 Movement with Stations')\n","\n","# Scatter plot for stations with labels in the top right corner\n","for lon, lat, label, color in zip(station_longitude, station_latitude, station_labels, station_colors):\n","    plt.scatter(lon, lat, color=color)\n","    plt.annotate(label, (lon, lat), fontsize=8, ha='left', va='bottom')\n","\n","# Add legend for green and red dots\n","plt.scatter([], [], color='green', label='Fish Detected')\n","plt.scatter([], [], color='red', label='Fish Not Detected')\n","plt.legend(loc='upper right')\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jcaACRieS82j"},"outputs":[],"source":["# Define the longitude and latitude arrays for stations\n","station_longitude = [20.55331, 20.60169, 20.6057, 20.64561, 20.64984, 20.68885, 20.68968, 20.71504, 20.7181, 20.75242, 20.75805, 20.79069, 20.79869, 20.807021, 20.82168, 20.83526, 20.84281]\n","station_latitude = [-34.26002, -34.35186, -34.34874, -34.35479, -34.3523, -34.35346, -34.35905, -34.36976, -34.37348, -34.39396, -34.39456, -34.40693, -34.40984, -34.406908, -34.3987, -34.39735, -34.40792]\n","station_labels = ['BT', 'B14', 'B13', 'B12', 'B11', 'B10', 'B9', 'B8', 'B7', 'B6', 'B5', 'B4', 'B3', 'BC', 'B2', 'Bd', 'B0']\n","station_colors = ['green'] * len(station_longitude)  # Initialize all stations as green\n","\n","# Define the stations to change the color\n","stations_to_change = ['BT', 'B14', 'B13', 'B12', 'B11', 'B10', 'B9', 'B8', 'B7', 'B6', 'B5', 'B4', 'BC', 'B2', 'Bd', 'B0']\n","\n","# Change the color of specified stations to red\n","for i, label in enumerate(station_labels):\n","    if label in stations_to_change:\n","        station_colors[i] = 'red'\n","\n","# Load the fish movement data\n","df = data\n","\n","# Filter the data for fishid \"A69-9001-23702\"\n","fish_data = df.loc[df['fishid'] == \"A69-9001-23702\"]\n","\n","# Create a plot for the fish\n","plt.figure(figsize=(6, 5))  # Adjust the figure size as per your preference\n","plt.plot(fish_data['lon'], fish_data['lat'])\n","plt.xlabel('Longitude')\n","plt.ylabel('Latitude')\n","plt.title('Fish A69-9001-23702 Movement with Stations')\n","\n","# Scatter plot for stations with labels in the top right corner\n","for lon, lat, label, color in zip(station_longitude, station_latitude, station_labels, station_colors):\n","    plt.scatter(lon, lat, color=color)\n","    plt.annotate(label, (lon, lat), fontsize=8, ha='left', va='bottom')\n","\n","# Add legend for green and red dots\n","plt.scatter([], [], color='green', label='Fish Detected')\n","plt.scatter([], [], color='red', label='Fish Not Detected')\n","plt.legend(loc='upper right')\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p3WjCBCgS82j"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cM1bBQz-S82j"},"outputs":[],"source":[]}],"metadata":{"colab":{"private_outputs":true,"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"}},"nbformat":4,"nbformat_minor":0}